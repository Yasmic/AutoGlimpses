[
  {
    "objectID": "C_Plus_Plus/index.html",
    "href": "C_Plus_Plus/index.html",
    "title": "C Plus Plus",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\ncircularLinkedList\n\n\n\n\n\n\n\nLinked-list\n\n\n\n\nlinkedlist\n\n\n\n\n\n\nNov 14, 2024\n\n\nYas Mi\n\n\n\n\n\n\n  \n\n\n\n\nLinkedlist Basics\n\n\n\n\n\n\n\nLinked-list\n\n\n\n\nlinkedlist\n\n\n\n\n\n\nNov 14, 2024\n\n\nYas Mi\n\n\n\n\n\n\n  \n\n\n\n\nMulti Threading\n\n\n\n\n\n\n\nMulti Threading\n\n\n\n\nThreading concepts\n\n\n\n\n\n\nSep 10, 2023\n\n\nYas Mi\n\n\n\n\n\n\n  \n\n\n\n\nGlimpse of C++\n\n\n\n\n\n\n\nBasics of c++\n\n\n\n\nBasics of c++\n\n\n\n\n\n\nAug 6, 2023\n\n\nYas Mi\n\n\n\n\n\n\n  \n\n\n\n\nAdvanced C++ study\n\n\n\n\n\n\n\nAdvanced C++ study\n\n\n\n\nTemplates,Lambda Functions\n\n\n\n\n\n\nAug 6, 2023\n\n\nYas Mi\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "C_Plus_Plus/Linked-list/circular_linkedlist.html",
    "href": "C_Plus_Plus/Linked-list/circular_linkedlist.html",
    "title": "circularLinkedList",
    "section": "",
    "text": "#include &lt;iostream&gt;\n\nclass Node\n{\npublic:\n    int data;\n    Node *next;\n\n    explicit Node(int data): data(data), next(nullptr)\n    {\n    }\n\n    Node(int data, Node *next): data(data), next(nullptr)\n    {\n    }\n};\n\nclass singleLinkedList\n{\npublic:\n    Node *head;\n\n    singleLinkedList(): head(nullptr)\n    {\n    }\n\n    void insertAtBeginning(int data)\n    {\n        auto *newNode = new Node(data);\n        if (head == nullptr)\n        {\n            head = newNode;\n            newNode-&gt;next=head;\n        }\n        else\n        {\n\n            Node * temp=head;\n            while(temp-&gt;next!=head)\n            {\n                temp=temp-&gt;next;\n            }\n            temp-&gt;next=newNode;\n            newNode-&gt;next=head;\n            head=newNode;\n\n        }\n    }\n\n    void insertAtEnd(int data)\n    {\n        auto newNode=new Node(data);\n        if (head == nullptr)\n        {\n            head = newNode;\n            newNode-&gt;next=head;\n        }\n        else\n        {\n            Node *temp = head;\n            while (temp-&gt;next != head)\n            {\n                temp = temp-&gt;next;\n            }\n            temp-&gt;next = newNode;\n            newNode-&gt;next=head;\n        }\n    }\n\n    void createLinearToCircular(void)\n    {\n        if (head == nullptr)\n        {\n            return;\n        }\n        else\n        {\n            Node *temp = head;\n            while (temp-&gt;next != nullptr)\n            {\n                temp = temp-&gt;next;\n            }\n\n            temp-&gt;next = head;\n        }\n    }\n\n    void createCycleinTheList(int pos)\n    {\n        if (head == nullptr)\n        {\n            return;\n        }\n        else\n        {\n            int currPos=1;\n            Node *temp = head;\n            Node* circNode = nullptr;\n            while (temp-&gt;next != nullptr)\n            {\n                if(currPos == pos)\n                    {\n                        circNode = temp;\n                    }\n                currPos++;\n                temp = temp-&gt;next;\n            }\n            temp-&gt;next = circNode;\n        }\n    }\n\n    void display(bool isCircular) const\n    {\n        if (head == nullptr)\n        {\n            std::cout &lt;&lt; \"List is empty\" &lt;&lt; std::endl;\n            return;\n        }\n\n        const Node *temp = head;\n        if (isCircular)\n        {\n            do\n            {\n                std::cout &lt;&lt; temp-&gt;data &lt;&lt; \" \";\n                temp = temp-&gt;next;\n            } while (temp != head);\n        }\n        else\n        {\n            while (temp != nullptr)\n            {\n                std::cout &lt;&lt; temp-&gt;data &lt;&lt; \" \";\n                temp = temp-&gt;next;\n            }\n        }\n        std::cout &lt;&lt; std::endl;\n    }\n\n    ~singleLinkedList()\n    {\n        if (head == nullptr)\n            return;\n\n        Node *temp = head;\n\n        // Break the circular link, if any\n        Node *start = head;\n        while (temp-&gt;next != head && temp-&gt;next != nullptr)  // Find the last node\n        {\n            temp = temp-&gt;next;\n        }\n        if (temp-&gt;next == head)  // If the list is circular, break the loop\n        {\n            temp-&gt;next = nullptr;\n        }\n\n        // Delete the nodes as a normal singly linked list\n        temp = head;\n        while (temp != nullptr)\n        {\n            Node *nextNode = temp-&gt;next;\n            delete temp;\n            temp = nextNode;\n        }\n    }\n    };\n\n\nint main()\n{\n    singleLinkedList obj;\n    obj.insertAtBeginning(12);\n    obj.insertAtEnd(24);\n    obj.insertAtEnd(36);\n    obj.insertAtEnd(48);\n    obj.insertAtEnd(94);\n    std::cout &lt;&lt; \"circular list\" &lt;&lt; std::endl;\n    obj.display(true);\n    return 0;\n}\nOutput :\nlist before modification\n12 24 36 48 94 \ncircular list\n12 24 36 48 94"
  },
  {
    "objectID": "C_Plus_Plus/Linked-list/circular_linkedlist.html#circular-linkedlist",
    "href": "C_Plus_Plus/Linked-list/circular_linkedlist.html#circular-linkedlist",
    "title": "circularLinkedList",
    "section": "",
    "text": "#include &lt;iostream&gt;\n\nclass Node\n{\npublic:\n    int data;\n    Node *next;\n\n    explicit Node(int data): data(data), next(nullptr)\n    {\n    }\n\n    Node(int data, Node *next): data(data), next(nullptr)\n    {\n    }\n};\n\nclass singleLinkedList\n{\npublic:\n    Node *head;\n\n    singleLinkedList(): head(nullptr)\n    {\n    }\n\n    void insertAtBeginning(int data)\n    {\n        auto *newNode = new Node(data);\n        if (head == nullptr)\n        {\n            head = newNode;\n            newNode-&gt;next=head;\n        }\n        else\n        {\n\n            Node * temp=head;\n            while(temp-&gt;next!=head)\n            {\n                temp=temp-&gt;next;\n            }\n            temp-&gt;next=newNode;\n            newNode-&gt;next=head;\n            head=newNode;\n\n        }\n    }\n\n    void insertAtEnd(int data)\n    {\n        auto newNode=new Node(data);\n        if (head == nullptr)\n        {\n            head = newNode;\n            newNode-&gt;next=head;\n        }\n        else\n        {\n            Node *temp = head;\n            while (temp-&gt;next != head)\n            {\n                temp = temp-&gt;next;\n            }\n            temp-&gt;next = newNode;\n            newNode-&gt;next=head;\n        }\n    }\n\n    void createLinearToCircular(void)\n    {\n        if (head == nullptr)\n        {\n            return;\n        }\n        else\n        {\n            Node *temp = head;\n            while (temp-&gt;next != nullptr)\n            {\n                temp = temp-&gt;next;\n            }\n\n            temp-&gt;next = head;\n        }\n    }\n\n    void createCycleinTheList(int pos)\n    {\n        if (head == nullptr)\n        {\n            return;\n        }\n        else\n        {\n            int currPos=1;\n            Node *temp = head;\n            Node* circNode = nullptr;\n            while (temp-&gt;next != nullptr)\n            {\n                if(currPos == pos)\n                    {\n                        circNode = temp;\n                    }\n                currPos++;\n                temp = temp-&gt;next;\n            }\n            temp-&gt;next = circNode;\n        }\n    }\n\n    void display(bool isCircular) const\n    {\n        if (head == nullptr)\n        {\n            std::cout &lt;&lt; \"List is empty\" &lt;&lt; std::endl;\n            return;\n        }\n\n        const Node *temp = head;\n        if (isCircular)\n        {\n            do\n            {\n                std::cout &lt;&lt; temp-&gt;data &lt;&lt; \" \";\n                temp = temp-&gt;next;\n            } while (temp != head);\n        }\n        else\n        {\n            while (temp != nullptr)\n            {\n                std::cout &lt;&lt; temp-&gt;data &lt;&lt; \" \";\n                temp = temp-&gt;next;\n            }\n        }\n        std::cout &lt;&lt; std::endl;\n    }\n\n    ~singleLinkedList()\n    {\n        if (head == nullptr)\n            return;\n\n        Node *temp = head;\n\n        // Break the circular link, if any\n        Node *start = head;\n        while (temp-&gt;next != head && temp-&gt;next != nullptr)  // Find the last node\n        {\n            temp = temp-&gt;next;\n        }\n        if (temp-&gt;next == head)  // If the list is circular, break the loop\n        {\n            temp-&gt;next = nullptr;\n        }\n\n        // Delete the nodes as a normal singly linked list\n        temp = head;\n        while (temp != nullptr)\n        {\n            Node *nextNode = temp-&gt;next;\n            delete temp;\n            temp = nextNode;\n        }\n    }\n    };\n\n\nint main()\n{\n    singleLinkedList obj;\n    obj.insertAtBeginning(12);\n    obj.insertAtEnd(24);\n    obj.insertAtEnd(36);\n    obj.insertAtEnd(48);\n    obj.insertAtEnd(94);\n    std::cout &lt;&lt; \"circular list\" &lt;&lt; std::endl;\n    obj.display(true);\n    return 0;\n}\nOutput :\nlist before modification\n12 24 36 48 94 \ncircular list\n12 24 36 48 94"
  },
  {
    "objectID": "C_Plus_Plus/Advanced/multi_threading.html",
    "href": "C_Plus_Plus/Advanced/multi_threading.html",
    "title": "Multi Threading",
    "section": "",
    "text": "Purpose of Mutex : A mutex is used to coordinate mutually exclusive access to resources by multiple threads of execution. The mutex class is used to protect shared data from corruption due to simultaneous access by multiple threads.\nPurpose of producer consumer idiom : To facilitate threads that produce data and threads that consume data using a single common and coordinated container In the producer-consumer idiom one thread produces data and another consumes data, using one container to hold the data.\nWhat is the difference between sleep_for and sleep_until? sleep_for will sleep for a specified interval; sleep_until will sleep until a specified point in time. Both functions are in the this_thread namespace and both use objects from the chrono library for their arguments.\nHow does async return values from a thread? async returns values in a future object async uses the promise and future paradigm to return values to the caller.\nthread::join() method use case? The join() method blocks execution of the caller until the thread completes.\nWhat types qualify for use with std::atomic? std::atomic requires a trivial type. All primitive types are trivial, including bool, int, float, and double. std::atomic works with any trivial type. Trivial types include primitives such as bool, int, float, and double, as well as any class that uses the default constructor, copy constructor, copy assignment, and destructor.\n\n\n\nThread is useful for parallelism\nThread shall be created by below methods\n\nFunction pointer\nLambda function\nFunctor\nNon static member function\nStatic member function\n\nJoin helps to include the thread to main thread here the main thread is main function , if join is not present the main thread continue to execute before waiting for the t1 thread to finish .\n#include&lt;thread&gt;\n#include&lt;mutex&gt;\n#include&lt;iostream&gt;\nusing namespace std;\n\nvoid countFunction()\n{\n    for(int i=0;i&lt;10;i++)\n    {\n        counter++;\n        cout&lt;&lt;\"count function\"&lt;&lt;endl;\n    }\n}\n\n\nint main()\n{\ncout&lt;&lt;\"Main thread called\"&lt;&lt;endl;\n//Thread creation using function pointer\nthread t1(countFunction);\nt1.join();\ncout&lt;&lt;\"Main thread continued\"&lt;&lt;endl;\n}\nThread creation\nclass fClass\n{\n    public:\n    void operator()(int x)\n    {\n        cout&lt;&lt;x&lt;&lt;endl;\n    }\n\n    void printf(int x)\n    {\n        cout&lt;&lt;x&lt;&lt;endl;\n    }\n\n\n    static void printSt(int x)\n    {\n        cout&lt;&lt;x&lt;&lt;endl;\n    }\n};\n\nvoid print(int x)\n{\ncout&lt;&lt;x&lt;&lt;endl;\n}\nint main()\n{\n    //Thread creation using function pointer\n    thread t1(print,10);\n    t1.join;\n   //Thread creation using lambda\n   thread t3(([](int x){cout&lt;&lt;x&lt;&lt;endl;}),10);\n    t3.join();\n    //Thread creation using functor \n    thread t3(fClass(),10);\n    t3.join();\n    //Thread creation using non static member function \n    fClass obj;\n    thread t4(&fClass::printf,&obj,10);\n    t4.join();\n    //Thread creation using static member\n    thread t5(fClass::printSt,10);\n}\n\n\n\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;thread&gt;\n\nvoid print(int x)\n{\n    cout&lt;&lt;x&lt;&lt;endl;\n    cout&lt;&lt;\"thread print\"&lt;&lt;endl;\n     this_thread::sleep_for(chrono::seconds(3));\n}\nint main()\n{\n    thread t1(print,10);\n    cout&lt;&lt;\"main\"&lt;&lt;endl;\n    t1.join();\n    cout&lt;&lt;\"main continued\"&lt;&lt;endl;\n}\nResult : main  thread print - (waiting for 5sec) it prints after join  main continued \nWhen the thread created it starts running the thread and the control comes back to the main thread(Parent thread) to execute if join is mentioned it will not execute further it waits for the tread to finish its job\nDouble time join is not allowed, so always check if the thread is joinable using \nif(t1.joinable )\n{\n    t1.join\n}\n\n\n\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;thread&gt;\n\nvoid print(int x)\n{\n    cout&lt;&lt;x&lt;&lt;endl;\n    cout&lt;&lt;\"thread print\"&lt;&lt;endl;\n     this_thread::sleep_for(chrono::seconds(3));\n     cout&lt;&lt;\"thread done\"&lt;&lt;endl;\n}\nint main()\n{\n    thread t1(print,10);\n    cout&lt;&lt;\"main\"&lt;&lt;endl;\n    t1.detach();\n    cout&lt;&lt;\"main continued\"&lt;&lt;endl;\n    return 0;\n}\nResult : main main continued \nThe result keep changing if we get this result which means the thread function print taking more time (probably due to the wait time given )to run than the main thread printing and returning\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;thread&gt;\n\nvoid print(int x)\n{\n    cout&lt;&lt;x&lt;&lt;endl;\n    cout&lt;&lt;\"thread print\"&lt;&lt;endl;\n     cout&lt;&lt;\"thread done\"&lt;&lt;endl;\n}\nint main()\n{\n    thread t1(print,10);\n    cout&lt;&lt;\"main\"&lt;&lt;endl;\n    t1.detach();\n    cout&lt;&lt;\"main continued\"&lt;&lt;endl;\n     this_thread::sleep_for(chrono::seconds(3));\n    return 0;\n}\nif the thread gets finished by 3seconds of wait period of main thread (PArent) Result could be  Main Main continued  Thread print  Thread done\nBut if the main function is returning before completing the thread then that thread will be suspended the result will be just main and main continued .\nAnd double time the detach is also not possible so always check if the thread is joinable if the thread is joinable then only the detaching also possible\n\n\n\nIf we create multiple threads in the program we donno which executes in what order\nMutual exclusion\nRace condition its a situation where two or more threads access to the same data and try to modify that data at the same time\nif there is any race condition we have to protect the data so that there wont be any unpredicted result\nMutex helps to avoid the race condition using the lock commands\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;thread&gt;\n#include&lt;mutex&gt;\nint counterdata=0;\nvoid countData(int x)\n{\n    counterdata++;\n}\nint main()\n{\n    thread t1(countData,10);\n    thread t2(countData,10);\n    t1.join();\n    t2.join();\n    cout&lt;&lt;counterdata&lt;&lt;endl;\n    return 0;\n} \ncountdata will be updated by both thread t1 and t2 that forms the race condition . In order to avoid that we have to use mutex .\nThe critical section or critical reqion is where the data is updated at the same time by the threads .. To avoid that we have to use lock and unlock\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;thread&gt;\n#include&lt;mutex&gt;\nusing namespace std;\nint counterdata=0;\nmutex mx;\nvoid countData(int x)\n{\n    mx.lock();\n    counterdata++;\n    mx.unlock();\n}\nint main()\n{\n    thread t1(countData,10);\n    thread t2(countData,10);\n    t1.join();\n    t2.join();\n    cout&lt;&lt;counterdata&lt;&lt;endl;\n    return 0;\n} \nHere which ever thred reaches first to the cpu then that thread lets say t1 will acquire the lock before t2.\ntry_lock If try_lock is used it returns true for the sucesfull lock aquisitions else return false.\nIf try_lock is not able to lock the mutex then it doesnt get blocked .\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;thread&gt;\n#include&lt;mutex&gt;\nusing namespace std;\nint counterdata=0;\nmutex mx;\nvoid countData()\n{\n    if(mx.try_lock())\n    {\n        counterdata++;\n        mx.unlock();\n    }\n \n}\nint main()\n{\n    thread t1(countData,10);\n    thread t2(countData,10);\n    t1.join();\n    t2.join();\n    cout&lt;&lt;counterdata&lt;&lt;endl;\n    return 0;\n} \nHere the result is so random , since the thread wont wait for the locking to complete , so the actual result might also change\nIf i have a single core then how the thread parallally executes in c++ ?\n\nOn a single-core machine, threads do not execute truly in parallel. Instead, what gives the illusion of parallelism is something called “time-slicing” or “preemptive multitasking.”\nContext Switching: The operating system rapidly switches between running threads. It gives each thread a little “slice” of time to execute. When a thread’s time slice is up, its current state (context) is saved, and the CPU starts executing another thread.\nConcurrency vs. Parallelism: It’s important to differentiate between concurrency and parallelism. Concurrency is about dealing with a lot of things at once (which can be achieved through mechanisms like context switching), while parallelism is about doing a lot of things at once (which requires multiple cores or processors).\nBenefits on Single Core: Even on a single-core machine, using threads can be beneficial. For instance, if one thread is waiting for I/O (like reading a file or waiting for a network response), another thread can use the CPU. This way, the CPU isn’t idly waiting and can be used more efficiently.\nOverhead: Using multiple threads introduces overhead because of the need for context switches, synchronization mechanisms, etc. On a single-core machine, overusing threads (especially for tasks that are purely computational) can even lead to worse performance due to this overhead.\nLanguages & Libraries: In C++ specifically, the standard  library gives you tools to create and manage threads. But the behavior in terms of how these threads are scheduled and executed depends on the operating system’s scheduler.\nCooperative Multitasking: This is another form of multitasking where tasks yield control periodically or when idle to enable multiple tasks to run in a single-threaded environment. This approach depends more on the tasks being well-behaved and giving up control often.\n\n\n\n\nIt tries to lock all the loackable objets passed one by one in given order\nstd::try_lock(lm1,lm2....lmn)\nIf locked sucesfully function returns -1 otherwise it will return mutex index number which was not able to lock . if any one of the mutex is unable to lock ,it will release all the mutex which were previously locked . if try_lockresults in exception ,unlock is called for any locked object before rethrowing \n#include&lt;thread&gt;\n#include&lt;mutex&gt;\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;condition_variable&gt;\nusing namespace std;\n\nmutex m1,m2;\nint global_data=0;\n\nvoid function_Add(int x,mutex &m,int v)\n{\n    for(int i=0;i&lt;4;i++)\n    {\n        m.lock();\n        x=x+v;\n        global_data=x;\n        m.unlock();\n\n    }\n}\n\nvoid function_trylock_print()\n{\n    int lockResult=try_lock(m1,m2);\n    //Checks if try_lock is sucesful\n    if(lockResult==-1)\n    {\n        cout&lt;&lt;global_data&lt;&lt;endl;\n    }\n    m1.unlock();\n    m2.unlock();\n}\n\nint main()\n{\n    thread th1(function_Add,20,ref(m1),1);\n    thread th2(function_Add,20,ref(m2),2);\n    thread th3(function_trylock_print);\n    th1.join();\n    th2.join();\n    th3.join();\n    return 0;\n}\n\ntry_lock_for() -Tries the lock for specified duration - if waits for the amount of time mentioned to get the lock . The threads tries to get the lock for time mentioned in try_lock_for . Its used for time critical operations\ntry_lock_until - Waits until specified timeout time has been reached or the lock is aquired which ever comes first .if lock is quired return true else false\n\n\n\n\n\nSame thread can lock one mutex multiple times using recursive_mutex\nThe lock and unlock should match in recursive_mutex\nNo of times locking is system specific , if we reach that many times it will return system_error if we call lock() , if we call try_lock then return false\n\nrecursive_mutex\n#include&lt;thread&gt;\n#include&lt;mutex&gt;\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;condition_variable&gt;\nusing namespace std;\n\nrecursive_mutex m;\n\nint function_recursion(int x)\n{\n    if(x&lt;=0)\n    {\n        return 1;\n    }\n    m.lock();\n    cout&lt;&lt;\"data=\"&lt;&lt;x&lt;&lt;endl;\n    function_recursion(--x);\n    m.unlock();\n}\n\nint main()\n{\n\n    thread th3(function_recursion,3);\n    thread th4(function_recursion,3);\n    th3.join();\n    th4.join();\n    return 0;\n}\n\n\n\nlock_guard&lt;mutex&gt;lock(m)where m is mutex - with lock_guard you dont have to unlock unlike the conventional way where we use unlockmethod - when the object is created it will lock the mutex ,the unlock happens in the destructor of the lock_guard ,it unlocks automatically when it goes out of scope since the object is created in stack.\n#include&lt;thread&gt;\n#include&lt;mutex&gt;\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;condition_variable&gt;\nusing namespace std;\n\nmutex m;\nint counter=0;\nvoid function_lock_guard(int x)\n{\n  lock_guard&lt;mutex&gt;lock(m);\n  for(int i=0;i&lt;x;i++)\n  {\n        counter++;\n        cout&lt;&lt;counter&lt;&lt;endl;\n  }\n}\n\nint main()\n{\n\n    thread th3(function_lock_guard,3);\n    thread th4(function_lock_guard,3);\n    th3.join();\n    th4.join();\n    return 0;\n}\n\nResult is : 1,2,3,4,5,6\n\n\n\n\nunique_lock&lt;mutex&gt;lock(m)where m is mutex it works just like the lock_guard\n\nLocking strategies \ndefer_lock -It does not lock the mutex ,locking should be done at later point\ntry_to_lock it aquires the mutex but without blocking \nadopt_lock it assumes the calling thread aquired the mutex\nit allows\n\ntime based locking such as  try_lock_for, try_lock_until\nRecurstive locking allowed \nMove the lock possible \nCondition_varaible -Notification to the threads \n#include&lt;thread&gt;\n#include&lt;mutex&gt;\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;condition_variable&gt;\nusing namespace std;\n\nmutex m;\nint counter=0;\nvoid function_unique_lock(int x)\n{\n  unique_lock&lt;mutex&gt;lock(m,defer_lock);//owning the mutex but it doesnt lock \n  lock.lock();\n  for(int i=0;i&lt;x;i++)\n  {\n        counter++;\n        cout&lt;&lt;counter&lt;&lt;endl;\n  }\n}\n\nint main()\n{\n\n    thread th3(function_unique_lock,3);\n    thread th4(function_unique_lock,3);\n    th3.join();\n    th4.join();\n    return 0;\n}\n\n\n\nPurpose  - Notify other threads notify_one() to single thread or notify_all() to all the thread - Waiting for some condition\nTo synchronise the thread all the thread should have common condition_variable\nIt uses unique_lock\nThe current thread waits and release the lock so that the other thread can execute\nIf we want to start particular thread to start first its best to use the condition_varaible since it wait on some condition variable\nfor this we can use wait ,wait_for ,wait_untilbased on our need\n\nThread Synchronisation example using condition_variable\n\nIn order to ensure thread synchronisation need to use condition_varaible In that wait and notify_allcommands wait takes argument lock and false to go for waiting and control will be given to next thread  once the notify_allcommand is executed the control gives back to the previous thread if the argument is true then the current thread wont wait and continue its execution \n#include&lt;thread&gt;\n#include&lt;mutex&gt;\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;condition_variable&gt;\nusing namespace std;\n\nstatic int counterdata=1;\n\nmutex mx;\ncondition_variable cv;\n\nvoid PrintEvenData(int n)\n{\n         \n    for(;counterdata&lt;n;)\n    {    \n        unique_lock&lt;mutex&gt; lock(mx);\n        cv.wait(lock,[](){return counterdata%2==0;});\n        cout&lt;&lt;counterdata&lt;&lt;endl;\n        counterdata++;\n        lock.unlock();\n        cv.notify_all();\n    }\n}\n\nvoid PrintOddData(int n)\n{\n         \n     for(;counterdata&lt;n;)\n    {    \n        unique_lock&lt;mutex&gt; lock(mx);\n        cv.wait(lock,[](){return counterdata%2==1;});\n        cout&lt;&lt;counterdata&lt;&lt;endl;\n        counterdata++;\n        lock.unlock();\n        cv.notify_all();\n    }\n   \n}\nint main()\n{\n    thread th1(PrintEvenData,20);\n    thread th2(PrintOddData,20);\n     th1.join();\n    th2.join();\n    return 0;\n}\n\n\nIn order to ensure thread synchronisation need to use condition_varaible In that wait and notify_allcommands wait takes argument lock and false to go for waiting and control will be given to next thread  once the notify_allcommand is executed the control gives back to the previous thread if the argument is true then the current thread wont wait and continue its execution  Best use is producer consumer problem\n#include&lt;thread&gt;\n#include&lt;mutex&gt;\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;condition_variable&gt;\nusing namespace std;\n\nstatic int counterdata=1;\n\nmutex mx;\ncondition_variable cv;\n\nvoid PrintEvenData(int n)\n{\n         \n    for(;counterdata&lt;n;)\n    {    \n        unique_lock&lt;mutex&gt; lock(mx);\n        cv.wait(lock,[](){return counterdata%2==0;});\n        cout&lt;&lt;counterdata&lt;&lt;endl;\n        counterdata++;\n        lock.unlock();//this is not needed since the unique_lock unlocks by itself in its destructor\n        cv.notify_all();//if more than one thread this could be used \n    }\n}\n\nvoid PrintOddData(int n)\n{\n         \n     for(;counterdata&lt;n;)\n    {    \n        unique_lock&lt;mutex&gt; lock(mx);\n        cv.wait(lock,[](){return counterdata%2==1;});\n        cout&lt;&lt;counterdata&lt;&lt;endl;\n        counterdata++;\n        lock.unlock();\n        cv.notify_all();\n    }\n   \n}\nint main()\n{\n    thread th1(PrintEvenData,20);\n    thread th2(PrintOddData,20);\n     th1.join();\n    th2.join();\n    return 0;\n}\n\n\n\n\nIn multiple resource sharing scenarios if the threads are holding the resource and not able to release which is deadlock .\n#include&lt;thread&gt;\n#include&lt;mutex&gt;\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;condition_variable&gt;\nusing namespace std;\n\nmutex m1;\nmutex m2;\nint counter=0;\nvoid function_one(int x)\n{\n  m1.lock();\n  this_thread::sleep_for(chrono::seconds(3));\n  m2.lock();\n  for(int i=0;i&lt;x;i++)\n  {\n        counter++;\n        cout&lt;&lt;counter&lt;&lt;endl;\n  }\n  cout&lt;&lt;\"critical section two\"&lt;&lt;endl;\n  m1.unlock();\n  m2.unlock();\n}\n\nvoid function_two(int x)\n{\n  m2.lock();\n   this_thread::sleep_for(chrono::seconds(3));\n  m1.lock();\n  for(int i=0;i&lt;x;i++)\n  {\n        counter++;\n        cout&lt;&lt;counter&lt;&lt;endl;\n  }\n  cout&lt;&lt;\"critical section one\"&lt;&lt;endl;\n  m1.unlock();\n  m2.unlock();\n}\nint main()\n{\n\n    thread th3(function_one,3);\n    thread th4(function_two,3);\n    th3.join();\n    th4.join();\n    return 0;\n}\n\nIn function_one() locks m1 and goes for sleep by the time function_two locks m2\nIn function_two() locks m2 and goes for sleep\nThe function_one() waits for unlocking of m2 to execute the code in the critical section\nThe function_two() also waiting for unlocking of m1 to execute the code in the critical section\nThis situation is nothing but deadlock\n\nTo avoid this we shouldnt change the order of mutex locking (m1 and m2 in both the function)\n\n\n\nCritical section is one or collection of program statement which should be executed by only one thread or process at a time. Thread/process synchronize to access critical section if the data is common between the threads it is critical section , and if the data is used only for reading then its not considered as critical section but if there is a write operation between threads to update the same data then it becomes critical section\n\nBelow is the example of race condition we donno exactly the value of counter ,it will be impossible to get 8 it might be 3 or 5\n\n\n#include&lt;thread&gt;\n#include&lt;iostream&gt;\nusing namespace std;\n\nint counter=0;\nvoid function_one(int x)\n{\n counter+=x;\n}\n\nint main()\n{\n\n    thread th3(function_one,3);\n    thread th4(function_one,5);\n    th3.join();\n    th4.join();\n    cout&lt;&lt;counter&lt;&lt;endl;\n    return 0;\n}\n\nHow to avoid this : using mutex\n\nmutex m1;\n\nint counter=0;\nvoid function_one(int x)\n{\n    m1.lock();\n    counter+=x;\n    m1.unlock();\n}\n\n\n\nint main()\n{\n\n    thread th3(function_one,3);\n    thread th4(function_one,5);\n    th3.join();\n    th4.join();\n    cout&lt;&lt;counter&lt;&lt;endl;\n    return 0;\n}\nHere lets say both the thread reached to lock at the same time , and one of them gets the access randomly to lock and access critical section lets say th1 got access then other thread is waiting and after writing counter it will release using unlock now the th2 can access by locking and continue to write .But here one thread is writing critical section at one time , only one thread at a time can execute if one of the thread dont unlock the other thread keeps waiting and goes to deadlock condition this is the reason the thread synchronisation is very important\n\nBut how do we ensure thread synchronisation without deadlock?\n\n\n\n\nIt allows to lock multiple mutex same time\nIt will not let to happen deadlock\nIt can use lock(), try_lock() or unlock()\nif one of them is not locked it will unlock all and tries another time by re arranging the sequence order of mutex locking . previously ,3 couldnt lock internally from next time when it tries it will try to lock first m3 then tries remaining and every time it ensures no deadlock scenario occurs.\n\nDeadlock example\n#include&lt;thread&gt;\n#include&lt;mutex&gt;\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;condition_variable&gt;\nusing namespace std;\n\nmutex m1;\nmutex m2;\n\nint counter=0;\nvoid function_one(int x)\n{\n    m2.lock();\n    this_thread::sleep_for(chrono::seconds(3));\n    m1.lock();\n    counter+=x;\n    m2.unlock();\n    m1.unlock();\n}\n\nvoid function_two(int x)\n{\n    m1.lock();\n    this_thread::sleep_for(chrono::seconds(3));\n    m2.lock();\n    counter+=x;\n    m1.unlock();\n    m2.unlock();\n}\n\nint main()\n{\n\n    thread th3(function_one,3);\n    thread th4(function_two,5);\n    th3.join();\n    th4.join();\n    cout&lt;&lt;counter&lt;&lt;endl;\n    return 0;\n}\n\nHow to avoid them\n\n#include&lt;thread&gt;\n#include&lt;mutex&gt;\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;condition_variable&gt;\nusing namespace std;\n\nmutex m1;\nmutex m2;\n\nint counter=0;\nvoid function_one(int x)\n{\n    lock(m1,m2);\n    this_thread::sleep_for(chrono::seconds(3));\n    counter+=x;\n    m1.unlock();\n    m2.unlock();\n\n}\n\nvoid function_two(int x)\n{\n   lock(m2,m1);\n    this_thread::sleep_for(chrono::seconds(3));\n    counter+=x;\n    m2.unlock();\n    m1.unlock();\n}\n\nint main()\n{\n\n    thread th3(function_one,3);\n    thread th4(function_two,5);\n    th3.join();\n    th4.join();\n    cout&lt;&lt;counter&lt;&lt;endl;\n    return 0;\n}\nExample\nNo deadlock  ex:1 - lock(m1,m2) - for thread 1 - lock(m1,m2)- for thread 2\nex:2 Thread1 - lock(m1,m2)-Th1 is locked m1\nThread 2 - lock(m2,m1)- Th2 is locked m2 it releases lock and tries after some time by the time thread 1 is released so the Th2 would be able to finish even it changes the order of locking and then release for Th1 vice versa\nDeadlock \n\n\n\n\n\nstd::promise Used to set values or exceptions\nstd::future It Wait for the promise It enquire promise if the values are available It gets the values from the promise\n\nHere is the simple program for promise and future to understand how the data is shared between two threads , the thread function_future which is calling getmethod internall waits until the data is available from the thread function_promise\n#include&lt;thread&gt;\n#include&lt;iostream&gt;\n#include &lt;future&gt;\n#include&lt;utility&gt;\n\nusing namespace std;\nvoid function_promise(promise&lt;int&gt;&&pObj)\n{\n  \npObj.set_value(10);\n\n}\n\nvoid function_future(future&lt;int&gt;&& obj)\n{\n   cout&lt;&lt;\"the value is=\"&lt;&lt;obj.get()&lt;&lt;endl;\n\n}\n\nint main()\n{\n    promise&lt;int&gt;pObj;\n    future&lt;int&gt;fObj=pObj.get_future();\n    thread t1(function_promise,move(pObj));\n    thread t2(function_future,move(fObj));\n    t1.join();\n    t2.join();\n    return 0;\n}\n\n\n\n\nProducer is the thread which gives the data Producer provides the data in the buffer\nConsumer is the thread which takes the data from the buffer in order to avoid the race condition here we use mutex Producer takes the lock and update the data and release mutex lock and notify to consumer .\n\nAfter the notification consumer goes and takes the data and consumer notify to producer back . - it goes until the producer wants to produce the data"
  },
  {
    "objectID": "C_Plus_Plus/Advanced/multi_threading.html#multi-threading",
    "href": "C_Plus_Plus/Advanced/multi_threading.html#multi-threading",
    "title": "Multi Threading",
    "section": "",
    "text": "Purpose of Mutex : A mutex is used to coordinate mutually exclusive access to resources by multiple threads of execution. The mutex class is used to protect shared data from corruption due to simultaneous access by multiple threads.\nPurpose of producer consumer idiom : To facilitate threads that produce data and threads that consume data using a single common and coordinated container In the producer-consumer idiom one thread produces data and another consumes data, using one container to hold the data.\nWhat is the difference between sleep_for and sleep_until? sleep_for will sleep for a specified interval; sleep_until will sleep until a specified point in time. Both functions are in the this_thread namespace and both use objects from the chrono library for their arguments.\nHow does async return values from a thread? async returns values in a future object async uses the promise and future paradigm to return values to the caller.\nthread::join() method use case? The join() method blocks execution of the caller until the thread completes.\nWhat types qualify for use with std::atomic? std::atomic requires a trivial type. All primitive types are trivial, including bool, int, float, and double. std::atomic works with any trivial type. Trivial types include primitives such as bool, int, float, and double, as well as any class that uses the default constructor, copy constructor, copy assignment, and destructor.\n\n\n\nThread is useful for parallelism\nThread shall be created by below methods\n\nFunction pointer\nLambda function\nFunctor\nNon static member function\nStatic member function\n\nJoin helps to include the thread to main thread here the main thread is main function , if join is not present the main thread continue to execute before waiting for the t1 thread to finish .\n#include&lt;thread&gt;\n#include&lt;mutex&gt;\n#include&lt;iostream&gt;\nusing namespace std;\n\nvoid countFunction()\n{\n    for(int i=0;i&lt;10;i++)\n    {\n        counter++;\n        cout&lt;&lt;\"count function\"&lt;&lt;endl;\n    }\n}\n\n\nint main()\n{\ncout&lt;&lt;\"Main thread called\"&lt;&lt;endl;\n//Thread creation using function pointer\nthread t1(countFunction);\nt1.join();\ncout&lt;&lt;\"Main thread continued\"&lt;&lt;endl;\n}\nThread creation\nclass fClass\n{\n    public:\n    void operator()(int x)\n    {\n        cout&lt;&lt;x&lt;&lt;endl;\n    }\n\n    void printf(int x)\n    {\n        cout&lt;&lt;x&lt;&lt;endl;\n    }\n\n\n    static void printSt(int x)\n    {\n        cout&lt;&lt;x&lt;&lt;endl;\n    }\n};\n\nvoid print(int x)\n{\ncout&lt;&lt;x&lt;&lt;endl;\n}\nint main()\n{\n    //Thread creation using function pointer\n    thread t1(print,10);\n    t1.join;\n   //Thread creation using lambda\n   thread t3(([](int x){cout&lt;&lt;x&lt;&lt;endl;}),10);\n    t3.join();\n    //Thread creation using functor \n    thread t3(fClass(),10);\n    t3.join();\n    //Thread creation using non static member function \n    fClass obj;\n    thread t4(&fClass::printf,&obj,10);\n    t4.join();\n    //Thread creation using static member\n    thread t5(fClass::printSt,10);\n}\n\n\n\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;thread&gt;\n\nvoid print(int x)\n{\n    cout&lt;&lt;x&lt;&lt;endl;\n    cout&lt;&lt;\"thread print\"&lt;&lt;endl;\n     this_thread::sleep_for(chrono::seconds(3));\n}\nint main()\n{\n    thread t1(print,10);\n    cout&lt;&lt;\"main\"&lt;&lt;endl;\n    t1.join();\n    cout&lt;&lt;\"main continued\"&lt;&lt;endl;\n}\nResult : main  thread print - (waiting for 5sec) it prints after join  main continued \nWhen the thread created it starts running the thread and the control comes back to the main thread(Parent thread) to execute if join is mentioned it will not execute further it waits for the tread to finish its job\nDouble time join is not allowed, so always check if the thread is joinable using \nif(t1.joinable )\n{\n    t1.join\n}\n\n\n\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;thread&gt;\n\nvoid print(int x)\n{\n    cout&lt;&lt;x&lt;&lt;endl;\n    cout&lt;&lt;\"thread print\"&lt;&lt;endl;\n     this_thread::sleep_for(chrono::seconds(3));\n     cout&lt;&lt;\"thread done\"&lt;&lt;endl;\n}\nint main()\n{\n    thread t1(print,10);\n    cout&lt;&lt;\"main\"&lt;&lt;endl;\n    t1.detach();\n    cout&lt;&lt;\"main continued\"&lt;&lt;endl;\n    return 0;\n}\nResult : main main continued \nThe result keep changing if we get this result which means the thread function print taking more time (probably due to the wait time given )to run than the main thread printing and returning\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;thread&gt;\n\nvoid print(int x)\n{\n    cout&lt;&lt;x&lt;&lt;endl;\n    cout&lt;&lt;\"thread print\"&lt;&lt;endl;\n     cout&lt;&lt;\"thread done\"&lt;&lt;endl;\n}\nint main()\n{\n    thread t1(print,10);\n    cout&lt;&lt;\"main\"&lt;&lt;endl;\n    t1.detach();\n    cout&lt;&lt;\"main continued\"&lt;&lt;endl;\n     this_thread::sleep_for(chrono::seconds(3));\n    return 0;\n}\nif the thread gets finished by 3seconds of wait period of main thread (PArent) Result could be  Main Main continued  Thread print  Thread done\nBut if the main function is returning before completing the thread then that thread will be suspended the result will be just main and main continued .\nAnd double time the detach is also not possible so always check if the thread is joinable if the thread is joinable then only the detaching also possible\n\n\n\nIf we create multiple threads in the program we donno which executes in what order\nMutual exclusion\nRace condition its a situation where two or more threads access to the same data and try to modify that data at the same time\nif there is any race condition we have to protect the data so that there wont be any unpredicted result\nMutex helps to avoid the race condition using the lock commands\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;thread&gt;\n#include&lt;mutex&gt;\nint counterdata=0;\nvoid countData(int x)\n{\n    counterdata++;\n}\nint main()\n{\n    thread t1(countData,10);\n    thread t2(countData,10);\n    t1.join();\n    t2.join();\n    cout&lt;&lt;counterdata&lt;&lt;endl;\n    return 0;\n} \ncountdata will be updated by both thread t1 and t2 that forms the race condition . In order to avoid that we have to use mutex .\nThe critical section or critical reqion is where the data is updated at the same time by the threads .. To avoid that we have to use lock and unlock\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;thread&gt;\n#include&lt;mutex&gt;\nusing namespace std;\nint counterdata=0;\nmutex mx;\nvoid countData(int x)\n{\n    mx.lock();\n    counterdata++;\n    mx.unlock();\n}\nint main()\n{\n    thread t1(countData,10);\n    thread t2(countData,10);\n    t1.join();\n    t2.join();\n    cout&lt;&lt;counterdata&lt;&lt;endl;\n    return 0;\n} \nHere which ever thred reaches first to the cpu then that thread lets say t1 will acquire the lock before t2.\ntry_lock If try_lock is used it returns true for the sucesfull lock aquisitions else return false.\nIf try_lock is not able to lock the mutex then it doesnt get blocked .\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;thread&gt;\n#include&lt;mutex&gt;\nusing namespace std;\nint counterdata=0;\nmutex mx;\nvoid countData()\n{\n    if(mx.try_lock())\n    {\n        counterdata++;\n        mx.unlock();\n    }\n \n}\nint main()\n{\n    thread t1(countData,10);\n    thread t2(countData,10);\n    t1.join();\n    t2.join();\n    cout&lt;&lt;counterdata&lt;&lt;endl;\n    return 0;\n} \nHere the result is so random , since the thread wont wait for the locking to complete , so the actual result might also change\nIf i have a single core then how the thread parallally executes in c++ ?\n\nOn a single-core machine, threads do not execute truly in parallel. Instead, what gives the illusion of parallelism is something called “time-slicing” or “preemptive multitasking.”\nContext Switching: The operating system rapidly switches between running threads. It gives each thread a little “slice” of time to execute. When a thread’s time slice is up, its current state (context) is saved, and the CPU starts executing another thread.\nConcurrency vs. Parallelism: It’s important to differentiate between concurrency and parallelism. Concurrency is about dealing with a lot of things at once (which can be achieved through mechanisms like context switching), while parallelism is about doing a lot of things at once (which requires multiple cores or processors).\nBenefits on Single Core: Even on a single-core machine, using threads can be beneficial. For instance, if one thread is waiting for I/O (like reading a file or waiting for a network response), another thread can use the CPU. This way, the CPU isn’t idly waiting and can be used more efficiently.\nOverhead: Using multiple threads introduces overhead because of the need for context switches, synchronization mechanisms, etc. On a single-core machine, overusing threads (especially for tasks that are purely computational) can even lead to worse performance due to this overhead.\nLanguages & Libraries: In C++ specifically, the standard  library gives you tools to create and manage threads. But the behavior in terms of how these threads are scheduled and executed depends on the operating system’s scheduler.\nCooperative Multitasking: This is another form of multitasking where tasks yield control periodically or when idle to enable multiple tasks to run in a single-threaded environment. This approach depends more on the tasks being well-behaved and giving up control often.\n\n\n\n\nIt tries to lock all the loackable objets passed one by one in given order\nstd::try_lock(lm1,lm2....lmn)\nIf locked sucesfully function returns -1 otherwise it will return mutex index number which was not able to lock . if any one of the mutex is unable to lock ,it will release all the mutex which were previously locked . if try_lockresults in exception ,unlock is called for any locked object before rethrowing \n#include&lt;thread&gt;\n#include&lt;mutex&gt;\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;condition_variable&gt;\nusing namespace std;\n\nmutex m1,m2;\nint global_data=0;\n\nvoid function_Add(int x,mutex &m,int v)\n{\n    for(int i=0;i&lt;4;i++)\n    {\n        m.lock();\n        x=x+v;\n        global_data=x;\n        m.unlock();\n\n    }\n}\n\nvoid function_trylock_print()\n{\n    int lockResult=try_lock(m1,m2);\n    //Checks if try_lock is sucesful\n    if(lockResult==-1)\n    {\n        cout&lt;&lt;global_data&lt;&lt;endl;\n    }\n    m1.unlock();\n    m2.unlock();\n}\n\nint main()\n{\n    thread th1(function_Add,20,ref(m1),1);\n    thread th2(function_Add,20,ref(m2),2);\n    thread th3(function_trylock_print);\n    th1.join();\n    th2.join();\n    th3.join();\n    return 0;\n}\n\ntry_lock_for() -Tries the lock for specified duration - if waits for the amount of time mentioned to get the lock . The threads tries to get the lock for time mentioned in try_lock_for . Its used for time critical operations\ntry_lock_until - Waits until specified timeout time has been reached or the lock is aquired which ever comes first .if lock is quired return true else false\n\n\n\n\n\nSame thread can lock one mutex multiple times using recursive_mutex\nThe lock and unlock should match in recursive_mutex\nNo of times locking is system specific , if we reach that many times it will return system_error if we call lock() , if we call try_lock then return false\n\nrecursive_mutex\n#include&lt;thread&gt;\n#include&lt;mutex&gt;\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;condition_variable&gt;\nusing namespace std;\n\nrecursive_mutex m;\n\nint function_recursion(int x)\n{\n    if(x&lt;=0)\n    {\n        return 1;\n    }\n    m.lock();\n    cout&lt;&lt;\"data=\"&lt;&lt;x&lt;&lt;endl;\n    function_recursion(--x);\n    m.unlock();\n}\n\nint main()\n{\n\n    thread th3(function_recursion,3);\n    thread th4(function_recursion,3);\n    th3.join();\n    th4.join();\n    return 0;\n}\n\n\n\nlock_guard&lt;mutex&gt;lock(m)where m is mutex - with lock_guard you dont have to unlock unlike the conventional way where we use unlockmethod - when the object is created it will lock the mutex ,the unlock happens in the destructor of the lock_guard ,it unlocks automatically when it goes out of scope since the object is created in stack.\n#include&lt;thread&gt;\n#include&lt;mutex&gt;\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;condition_variable&gt;\nusing namespace std;\n\nmutex m;\nint counter=0;\nvoid function_lock_guard(int x)\n{\n  lock_guard&lt;mutex&gt;lock(m);\n  for(int i=0;i&lt;x;i++)\n  {\n        counter++;\n        cout&lt;&lt;counter&lt;&lt;endl;\n  }\n}\n\nint main()\n{\n\n    thread th3(function_lock_guard,3);\n    thread th4(function_lock_guard,3);\n    th3.join();\n    th4.join();\n    return 0;\n}\n\nResult is : 1,2,3,4,5,6\n\n\n\n\nunique_lock&lt;mutex&gt;lock(m)where m is mutex it works just like the lock_guard\n\nLocking strategies \ndefer_lock -It does not lock the mutex ,locking should be done at later point\ntry_to_lock it aquires the mutex but without blocking \nadopt_lock it assumes the calling thread aquired the mutex\nit allows\n\ntime based locking such as  try_lock_for, try_lock_until\nRecurstive locking allowed \nMove the lock possible \nCondition_varaible -Notification to the threads \n#include&lt;thread&gt;\n#include&lt;mutex&gt;\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;condition_variable&gt;\nusing namespace std;\n\nmutex m;\nint counter=0;\nvoid function_unique_lock(int x)\n{\n  unique_lock&lt;mutex&gt;lock(m,defer_lock);//owning the mutex but it doesnt lock \n  lock.lock();\n  for(int i=0;i&lt;x;i++)\n  {\n        counter++;\n        cout&lt;&lt;counter&lt;&lt;endl;\n  }\n}\n\nint main()\n{\n\n    thread th3(function_unique_lock,3);\n    thread th4(function_unique_lock,3);\n    th3.join();\n    th4.join();\n    return 0;\n}\n\n\n\nPurpose  - Notify other threads notify_one() to single thread or notify_all() to all the thread - Waiting for some condition\nTo synchronise the thread all the thread should have common condition_variable\nIt uses unique_lock\nThe current thread waits and release the lock so that the other thread can execute\nIf we want to start particular thread to start first its best to use the condition_varaible since it wait on some condition variable\nfor this we can use wait ,wait_for ,wait_untilbased on our need\n\nThread Synchronisation example using condition_variable\n\nIn order to ensure thread synchronisation need to use condition_varaible In that wait and notify_allcommands wait takes argument lock and false to go for waiting and control will be given to next thread  once the notify_allcommand is executed the control gives back to the previous thread if the argument is true then the current thread wont wait and continue its execution \n#include&lt;thread&gt;\n#include&lt;mutex&gt;\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;condition_variable&gt;\nusing namespace std;\n\nstatic int counterdata=1;\n\nmutex mx;\ncondition_variable cv;\n\nvoid PrintEvenData(int n)\n{\n         \n    for(;counterdata&lt;n;)\n    {    \n        unique_lock&lt;mutex&gt; lock(mx);\n        cv.wait(lock,[](){return counterdata%2==0;});\n        cout&lt;&lt;counterdata&lt;&lt;endl;\n        counterdata++;\n        lock.unlock();\n        cv.notify_all();\n    }\n}\n\nvoid PrintOddData(int n)\n{\n         \n     for(;counterdata&lt;n;)\n    {    \n        unique_lock&lt;mutex&gt; lock(mx);\n        cv.wait(lock,[](){return counterdata%2==1;});\n        cout&lt;&lt;counterdata&lt;&lt;endl;\n        counterdata++;\n        lock.unlock();\n        cv.notify_all();\n    }\n   \n}\nint main()\n{\n    thread th1(PrintEvenData,20);\n    thread th2(PrintOddData,20);\n     th1.join();\n    th2.join();\n    return 0;\n}\n\n\nIn order to ensure thread synchronisation need to use condition_varaible In that wait and notify_allcommands wait takes argument lock and false to go for waiting and control will be given to next thread  once the notify_allcommand is executed the control gives back to the previous thread if the argument is true then the current thread wont wait and continue its execution  Best use is producer consumer problem\n#include&lt;thread&gt;\n#include&lt;mutex&gt;\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;condition_variable&gt;\nusing namespace std;\n\nstatic int counterdata=1;\n\nmutex mx;\ncondition_variable cv;\n\nvoid PrintEvenData(int n)\n{\n         \n    for(;counterdata&lt;n;)\n    {    \n        unique_lock&lt;mutex&gt; lock(mx);\n        cv.wait(lock,[](){return counterdata%2==0;});\n        cout&lt;&lt;counterdata&lt;&lt;endl;\n        counterdata++;\n        lock.unlock();//this is not needed since the unique_lock unlocks by itself in its destructor\n        cv.notify_all();//if more than one thread this could be used \n    }\n}\n\nvoid PrintOddData(int n)\n{\n         \n     for(;counterdata&lt;n;)\n    {    \n        unique_lock&lt;mutex&gt; lock(mx);\n        cv.wait(lock,[](){return counterdata%2==1;});\n        cout&lt;&lt;counterdata&lt;&lt;endl;\n        counterdata++;\n        lock.unlock();\n        cv.notify_all();\n    }\n   \n}\nint main()\n{\n    thread th1(PrintEvenData,20);\n    thread th2(PrintOddData,20);\n     th1.join();\n    th2.join();\n    return 0;\n}\n\n\n\n\nIn multiple resource sharing scenarios if the threads are holding the resource and not able to release which is deadlock .\n#include&lt;thread&gt;\n#include&lt;mutex&gt;\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;condition_variable&gt;\nusing namespace std;\n\nmutex m1;\nmutex m2;\nint counter=0;\nvoid function_one(int x)\n{\n  m1.lock();\n  this_thread::sleep_for(chrono::seconds(3));\n  m2.lock();\n  for(int i=0;i&lt;x;i++)\n  {\n        counter++;\n        cout&lt;&lt;counter&lt;&lt;endl;\n  }\n  cout&lt;&lt;\"critical section two\"&lt;&lt;endl;\n  m1.unlock();\n  m2.unlock();\n}\n\nvoid function_two(int x)\n{\n  m2.lock();\n   this_thread::sleep_for(chrono::seconds(3));\n  m1.lock();\n  for(int i=0;i&lt;x;i++)\n  {\n        counter++;\n        cout&lt;&lt;counter&lt;&lt;endl;\n  }\n  cout&lt;&lt;\"critical section one\"&lt;&lt;endl;\n  m1.unlock();\n  m2.unlock();\n}\nint main()\n{\n\n    thread th3(function_one,3);\n    thread th4(function_two,3);\n    th3.join();\n    th4.join();\n    return 0;\n}\n\nIn function_one() locks m1 and goes for sleep by the time function_two locks m2\nIn function_two() locks m2 and goes for sleep\nThe function_one() waits for unlocking of m2 to execute the code in the critical section\nThe function_two() also waiting for unlocking of m1 to execute the code in the critical section\nThis situation is nothing but deadlock\n\nTo avoid this we shouldnt change the order of mutex locking (m1 and m2 in both the function)\n\n\n\nCritical section is one or collection of program statement which should be executed by only one thread or process at a time. Thread/process synchronize to access critical section if the data is common between the threads it is critical section , and if the data is used only for reading then its not considered as critical section but if there is a write operation between threads to update the same data then it becomes critical section\n\nBelow is the example of race condition we donno exactly the value of counter ,it will be impossible to get 8 it might be 3 or 5\n\n\n#include&lt;thread&gt;\n#include&lt;iostream&gt;\nusing namespace std;\n\nint counter=0;\nvoid function_one(int x)\n{\n counter+=x;\n}\n\nint main()\n{\n\n    thread th3(function_one,3);\n    thread th4(function_one,5);\n    th3.join();\n    th4.join();\n    cout&lt;&lt;counter&lt;&lt;endl;\n    return 0;\n}\n\nHow to avoid this : using mutex\n\nmutex m1;\n\nint counter=0;\nvoid function_one(int x)\n{\n    m1.lock();\n    counter+=x;\n    m1.unlock();\n}\n\n\n\nint main()\n{\n\n    thread th3(function_one,3);\n    thread th4(function_one,5);\n    th3.join();\n    th4.join();\n    cout&lt;&lt;counter&lt;&lt;endl;\n    return 0;\n}\nHere lets say both the thread reached to lock at the same time , and one of them gets the access randomly to lock and access critical section lets say th1 got access then other thread is waiting and after writing counter it will release using unlock now the th2 can access by locking and continue to write .But here one thread is writing critical section at one time , only one thread at a time can execute if one of the thread dont unlock the other thread keeps waiting and goes to deadlock condition this is the reason the thread synchronisation is very important\n\nBut how do we ensure thread synchronisation without deadlock?\n\n\n\n\nIt allows to lock multiple mutex same time\nIt will not let to happen deadlock\nIt can use lock(), try_lock() or unlock()\nif one of them is not locked it will unlock all and tries another time by re arranging the sequence order of mutex locking . previously ,3 couldnt lock internally from next time when it tries it will try to lock first m3 then tries remaining and every time it ensures no deadlock scenario occurs.\n\nDeadlock example\n#include&lt;thread&gt;\n#include&lt;mutex&gt;\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;condition_variable&gt;\nusing namespace std;\n\nmutex m1;\nmutex m2;\n\nint counter=0;\nvoid function_one(int x)\n{\n    m2.lock();\n    this_thread::sleep_for(chrono::seconds(3));\n    m1.lock();\n    counter+=x;\n    m2.unlock();\n    m1.unlock();\n}\n\nvoid function_two(int x)\n{\n    m1.lock();\n    this_thread::sleep_for(chrono::seconds(3));\n    m2.lock();\n    counter+=x;\n    m1.unlock();\n    m2.unlock();\n}\n\nint main()\n{\n\n    thread th3(function_one,3);\n    thread th4(function_two,5);\n    th3.join();\n    th4.join();\n    cout&lt;&lt;counter&lt;&lt;endl;\n    return 0;\n}\n\nHow to avoid them\n\n#include&lt;thread&gt;\n#include&lt;mutex&gt;\n#include&lt;iostream&gt;\n#include&lt;chrono&gt;\n#include&lt;condition_variable&gt;\nusing namespace std;\n\nmutex m1;\nmutex m2;\n\nint counter=0;\nvoid function_one(int x)\n{\n    lock(m1,m2);\n    this_thread::sleep_for(chrono::seconds(3));\n    counter+=x;\n    m1.unlock();\n    m2.unlock();\n\n}\n\nvoid function_two(int x)\n{\n   lock(m2,m1);\n    this_thread::sleep_for(chrono::seconds(3));\n    counter+=x;\n    m2.unlock();\n    m1.unlock();\n}\n\nint main()\n{\n\n    thread th3(function_one,3);\n    thread th4(function_two,5);\n    th3.join();\n    th4.join();\n    cout&lt;&lt;counter&lt;&lt;endl;\n    return 0;\n}\nExample\nNo deadlock  ex:1 - lock(m1,m2) - for thread 1 - lock(m1,m2)- for thread 2\nex:2 Thread1 - lock(m1,m2)-Th1 is locked m1\nThread 2 - lock(m2,m1)- Th2 is locked m2 it releases lock and tries after some time by the time thread 1 is released so the Th2 would be able to finish even it changes the order of locking and then release for Th1 vice versa\nDeadlock \n\n\n\n\n\nstd::promise Used to set values or exceptions\nstd::future It Wait for the promise It enquire promise if the values are available It gets the values from the promise\n\nHere is the simple program for promise and future to understand how the data is shared between two threads , the thread function_future which is calling getmethod internall waits until the data is available from the thread function_promise\n#include&lt;thread&gt;\n#include&lt;iostream&gt;\n#include &lt;future&gt;\n#include&lt;utility&gt;\n\nusing namespace std;\nvoid function_promise(promise&lt;int&gt;&&pObj)\n{\n  \npObj.set_value(10);\n\n}\n\nvoid function_future(future&lt;int&gt;&& obj)\n{\n   cout&lt;&lt;\"the value is=\"&lt;&lt;obj.get()&lt;&lt;endl;\n\n}\n\nint main()\n{\n    promise&lt;int&gt;pObj;\n    future&lt;int&gt;fObj=pObj.get_future();\n    thread t1(function_promise,move(pObj));\n    thread t2(function_future,move(fObj));\n    t1.join();\n    t2.join();\n    return 0;\n}\n\n\n\n\nProducer is the thread which gives the data Producer provides the data in the buffer\nConsumer is the thread which takes the data from the buffer in order to avoid the race condition here we use mutex Producer takes the lock and update the data and release mutex lock and notify to consumer .\n\nAfter the notification consumer goes and takes the data and consumer notify to producer back . - it goes until the producer wants to produce the data"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "This is about me"
  },
  {
    "objectID": "Autosar/index.html",
    "href": "Autosar/index.html",
    "title": "Autosar",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nDiagnostic communication manager\n\n\n\n\n\n\n\nDiagnostics\n\n\n\n\nDCM\n\n\n\n\n\n\nSep 16, 2023\n\n\nYasmi\n\n\n\n\n\n\n  \n\n\n\n\nDiagnostic event manager\n\n\n\n\n\n\n\nDiagnostics\n\n\n\n\nDEM\n\n\n\n\n\n\nSep 16, 2023\n\n\nYasmi\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Autosar/DCM.html",
    "href": "Autosar/DCM.html",
    "title": "Diagnostic communication manager",
    "section": "",
    "text": "Diagnostic session control module ensures diagnostic data flow and manages the diagnostic states, especially diagnostic sessions and security states .\nThe DCM module provides the OSI-layers 5 to 7\nOSI Layers and Diagnostic Protocols linking\n\n7- UDS 14229\n6-\n5- ISO 15765-3 - UDS on CAN\n4- ISO 15765-2\n3- ISO 15765-2\n2- CAN procotol, LIN Protocol, Flexray, MOST\n1- CAN procotol, LIN Protocol, Flexray, MOST \n\nThe dcm module receives diagnostic messages from the pdur module . once the dcm gets all the data it sends a message back throught he PduR module\nPdur (protocol data unit router) : The PduR module provides functions to trasmit and receive diagnositc data\nCommunication Manager(ComM): The ComM module provides functions such that the dcm can indicate the states “active” and “inactive” for diagnostic communication\nDCM handles the communication requirements such as Full/Silent/No-Communication. dcm module provides the functionality to enable and disable diagnositc communication if requested by the ComM module.\nDCM indicates to the BswM a communication mode change and notifies if the dcm is initailised due to jump from bootloader to application\n\n\n\nIf the diagnostic service is not sucesful due to any reason the corresponding NRC will be set and sent along with response to the diagnostic request\n\n\n\n\nDCM is devided in to 3 parts\n\n\nDSL-Diagnostic Session Layer\n\n\ncontrols diagnostic protocol timing and manages the security and sessions\n\n\nDiagnostic Service Dispatcher\n\n\nreceives new diagnositc request over a network and forwards it to a data processor\nTransmits a diagnositc response over a netowork when triggered by the data processor(DSP)\n\n\nDiagnostic Service Processing\n\n\nThe DSP submodule handles the actual diagnostic service requests . \n\n\n\n\n\n\n\nSessions handling as required by ISO 14229 and ISO 15765-3\nApplication layer timing handling as required by ISO 14229 and ISO 15765-3\nSpecific response behabiors as required by iso 14229 and iso 15765-3\n\n\n\n\nThe DSL has the following interaction wwith other modules : ##### PduR Module : - PduR module provides data of incoming diagnostic requests - The DSL submodule triggers output of diagnostic responses ##### DSD Submodule : - The DSL informs the dsd about incoming requests and provides the data - the DSD submodule triggers output of diagnostic responses ##### DSP submodule : - The DSL provides access to security and session state ##### ComM module : - The DSL guarantees the communication behavior required by the ComM module\n\n\n\n\n\n\nForwards request from the PduR module to DSD\nConcurrent test present (Keep alive logic - 3E service from ISO 14229) - if the 3E service requested with suppressPosRspMsgIndication bit set to be true (subfunction 0x80) ,DSL reset S3 server timing. also it shall not forward this request to DSD fof further interpretation\n\n\n\n\n\nForwards responses from the dsd to the PduR - via api PduR_DcmTransmit\nGuarantee response timing to tester if the service takes more time to respond then DSL shall send NRC 0x78 when reaching the response time P2 server max( DcmDspSessionP2ServerMax) from the next 0x78 waits for P2* server timeDcmDspSessionP2StarServerMax . DSL sends the negative responses as required from a separate buffer. The Max number of response pending(0x78) is configurable using DcmDslDiagRespMaxNumRespPend in order to avoid the deadlocks in the application. Once it reaches the Resp pending counter it shall send NRC (0x10) indicating general reject.\n\n\n\n\n\nManage security level\n\n\n\n\n\nManage session state :DSL get the current active session via Dcm_GetSesCtrlType() and set a new session through DslInternal_SetSesCtrlType() During dcm initialisation the default state is et which is Default session(0x01) when ever a non deault session is active and when the session timeout (S3 server)timing reaches without receiving any diag request , the DSL shall reset to the deault session by calling mode switch api of mode switch interface\nKeep track of active nond efault sessions\nAllow modifying timings DCM mdoule handle the following protocol timing parameter P2ServerMin,P2ServerMax,P2*ServerMin,P2*ServerMax,S3Server Generally these parameter set as\n\n\n\n\n\nHandling of Full/Silent/No Communication\nIndicating of active/inactive diagnostic\nEnabling/Disabling all kinds of diagnostic transmissions\n\n\n\n\n\n\nIt checks the validity of an incoming diagnostic request such as - Verification of diagnostic session - Security access levels - Application permission And keeps track of the progress of a service request execution\nThe DSD shall process only valid requests and shall reject invalid ones\n\n\n\nReceive a request message and transmit positive response message\n\nThe DSD ensures the validity of the request message.In this case if the request is valid the response will be positive .The request will be forwarded to the data process in the DSP. after DSP completes it triggers the transmission of response message by the DSD. If the response processing takes more time by the DSP may be waiting for read/write operation to eeprom then the response pending is covered by the DSL . When the request diag received the corresponding DcmPduId is blocked by the DSL .During the processing of this request , no other request of the same protocol type can be received, until the corresponding response message is sent and the DcmPduId if released again\n\nReceive a request message and supress the positive response\n\nIf the suppress positive response bit is set in the diag request in msb bit of sub function parameter .this kind of message completely handled by the DSD\n\nReceieve a request message and suppress the negative response\n\nIn case of functional addressing the DSD shall suppress the negative response for NRC 0x11 , 0x12 and 0x31\n\nReceive a request messahe and trasmit the negative response message\n\nDiag request is not valid or any condition not met to send the positive response the negative responses will be sent . In this case the DSP trigger a negative response with nrc indicating why the request was rejected . In case of 0x22 service if more than one did read operation is requested and if not all of the requested read did not failed only for the passed did the response will be sent .\n\nSend a positive response message without corresponding request\n\nThere are two services in the UDS protocol where multiole responses are sent for only one request . One service is used to enable(and disable)an event or time triggered transmission of another service , which is sent byt he ECU without a corresponding request. These services are \n\nRead Data by periodic identifier(0x2A)\nReponse on Event(0x86) These service handling is controlled by the DSL.However,DSD also provides the possibility to generate a response without a corresponding request.\n\n\nSegemented responses(Paged buffer):\n\nServices such as 0x19 and 0x36 exchange huge amount of data. So in this case the ecu internal buffer must be large enough to keep the longest data message which is to be exchnaged and the complete buffer is filled before the transmission is started . In a more RAM memory saving approach the buffer is filled only partly , transmitted partly and then refilled partly and so on. This paging mechanism rewuires only a reduced amount of memory but demands a well defined reaction time for buffer refilling . The user can decide whether to use the linear buffer or paged bugger for diagnostic\n\n#### DSD interaction with other modules\n\nDelegates the processing of request to the DSP\nKeeps track of request processing\nTransmit the response of the application to the DSL\n\n#### Functional description\n\nThe DSD shall be triggered by the DSL , if a new diagnostic message is recognised .\nThe DSD will sart processing by analyzing the diagnostic service indentifier contained in the received diagnositc message\nif the newly received the diagnositc request sid is not supported then the DSD shall transmit the negative response with NRC 0x11 to the DSL.\nVerification Functionality :The DSD accept service only if below 3 verifications are passed\n\nVerification of the Diagnostic session: On receiving the uds request dsd gets the current diagnostic session using api Dcm_GetSesCtrlType and verify whether the requested service and sub function are allowed in the current diagnostic session or not . (Note :0x10 service handling not part of DSD) If the received diag service is not allowed in the current diag session the DSD transmit the negative response with NRC 0x7F (service not supported in the active session)to the DSL submodule. If the received diag service is allowed in the current diag session but the sub function is not allowed in the current diag session then the DSD transmit the negative response with NRC 0x7E (sub function not supported in the active session)to the DSL submodule.\nVerification of the service security access levels:\n\nThe DSD checks the current security level with api Dcm_GetSecurityLevel() If the received diag service is not allowed in the current security level then the DSD shall transmit negative response with NRC 0x33 (Security access denied) to the DSL submodule\n\nIf the received diag service is n allowed in the current security level but the requested sub function is not allowed then the DSD shall transmit negative response with NRC 0x33 (Security access denied) to the DSL submodule DSD checks whether subfunction supported , if not supported NRC 0x12 will be sent . DSD checks minimum message length\nVerification of the application environment/Permission Before processing the diag request the application requested to check permission /environment eg: if ecu is in run state the diag service execution not allowed , vehicle speed is higher then the service is not allowed to execute(eg : service 11)\n\n\nThe DSD pass the diag request to DSP service interpretor\nThe execution of the DSP service interpreter can have the results\n\nPositive result or\nNegative result\n\nFollowing possible responses can be assembled\n\nPositive response : DSP indicate calling Dcm_ExternalProcessingDone().The parameter Dcm_MsgContextType contains the diagnostic (response)messgae . Then the DSD adds the response SIDand then response data stream (returned by the application)in the parameter Dcm_MsgContextType\nNegative response : The DSP triggers specific NRC to the DSD . The DSD handle all the supported NRC from the application and defined in the Dcm_NegativeResponseCodeType.\nSuppression of response in case of a negative result of the execution and active functional addressing the dsd submodule shall activate the suppression of the following negative responses:\n\n\nNRC 0x011 - service not supported\nNRC 0x12 - subfunction not supported\nNRC 0x31 - request out of range\n\n\nno Response :\nInitiate transmission\n\nthe DSD shall forward the diagnostic(response)message (positive or negative response) to the DSL.\nthe DSL shall forward the diagnostic(response)message (positive or negative response)further to the PduR module by executing a DSL transmit functionality.\nThe DSL will receive the confirmation by the PduR upon forwarding the dada\n\nthe DSL shall forward the received confirmation from the PduR to the dsd submodule.\nthe dsd shall forward the confirmation via the internal function DspInternal_DcmConfirmation() to the DSP submodule.\nIn case no diagnostic(response)message shall be sent(suppression of responses)the DSL submodule shall not transmit any response.\n\n\n\n\n\n\n\n\nWhen dsd request the dsp to process the diag request .it executed following basic process 1. analyze the received request message 2. check format and whether the addressed subfunction is supported 3. aquire data or execute the required function call on the DEM, SW-Cs or other BSW modules 4. assemble the response\n\nThe DSP submodule will check for appropriate message length and structure before executing the requested command . the DSP triggers a negative response with NRC 0x13 when the analysis of the request message results in formatting or length failure.\nif the paged-buffer mechanism is used the DSP submodule shall determine the overall response length before any data is passed to the DSD submodule respectively. The DSP submodule shall confirm the completion of the request processing with the function call Dcm_ExternalProcessingDone()"
  },
  {
    "objectID": "Autosar/DCM.html#description",
    "href": "Autosar/DCM.html#description",
    "title": "Diagnostic communication manager",
    "section": "",
    "text": "Diagnostic session control module ensures diagnostic data flow and manages the diagnostic states, especially diagnostic sessions and security states .\nThe DCM module provides the OSI-layers 5 to 7\nOSI Layers and Diagnostic Protocols linking\n\n7- UDS 14229\n6-\n5- ISO 15765-3 - UDS on CAN\n4- ISO 15765-2\n3- ISO 15765-2\n2- CAN procotol, LIN Protocol, Flexray, MOST\n1- CAN procotol, LIN Protocol, Flexray, MOST \n\nThe dcm module receives diagnostic messages from the pdur module . once the dcm gets all the data it sends a message back throught he PduR module\nPdur (protocol data unit router) : The PduR module provides functions to trasmit and receive diagnositc data\nCommunication Manager(ComM): The ComM module provides functions such that the dcm can indicate the states “active” and “inactive” for diagnostic communication\nDCM handles the communication requirements such as Full/Silent/No-Communication. dcm module provides the functionality to enable and disable diagnositc communication if requested by the ComM module.\nDCM indicates to the BswM a communication mode change and notifies if the dcm is initailised due to jump from bootloader to application\n\n\n\nIf the diagnostic service is not sucesful due to any reason the corresponding NRC will be set and sent along with response to the diagnostic request\n\n\n\n\nDCM is devided in to 3 parts\n\n\nDSL-Diagnostic Session Layer\n\n\ncontrols diagnostic protocol timing and manages the security and sessions\n\n\nDiagnostic Service Dispatcher\n\n\nreceives new diagnositc request over a network and forwards it to a data processor\nTransmits a diagnositc response over a netowork when triggered by the data processor(DSP)\n\n\nDiagnostic Service Processing\n\n\nThe DSP submodule handles the actual diagnostic service requests . \n\n\n\n\n\n\n\nSessions handling as required by ISO 14229 and ISO 15765-3\nApplication layer timing handling as required by ISO 14229 and ISO 15765-3\nSpecific response behabiors as required by iso 14229 and iso 15765-3\n\n\n\n\nThe DSL has the following interaction wwith other modules : ##### PduR Module : - PduR module provides data of incoming diagnostic requests - The DSL submodule triggers output of diagnostic responses ##### DSD Submodule : - The DSL informs the dsd about incoming requests and provides the data - the DSD submodule triggers output of diagnostic responses ##### DSP submodule : - The DSL provides access to security and session state ##### ComM module : - The DSL guarantees the communication behavior required by the ComM module\n\n\n\n\n\n\nForwards request from the PduR module to DSD\nConcurrent test present (Keep alive logic - 3E service from ISO 14229) - if the 3E service requested with suppressPosRspMsgIndication bit set to be true (subfunction 0x80) ,DSL reset S3 server timing. also it shall not forward this request to DSD fof further interpretation\n\n\n\n\n\nForwards responses from the dsd to the PduR - via api PduR_DcmTransmit\nGuarantee response timing to tester if the service takes more time to respond then DSL shall send NRC 0x78 when reaching the response time P2 server max( DcmDspSessionP2ServerMax) from the next 0x78 waits for P2* server timeDcmDspSessionP2StarServerMax . DSL sends the negative responses as required from a separate buffer. The Max number of response pending(0x78) is configurable using DcmDslDiagRespMaxNumRespPend in order to avoid the deadlocks in the application. Once it reaches the Resp pending counter it shall send NRC (0x10) indicating general reject.\n\n\n\n\n\nManage security level\n\n\n\n\n\nManage session state :DSL get the current active session via Dcm_GetSesCtrlType() and set a new session through DslInternal_SetSesCtrlType() During dcm initialisation the default state is et which is Default session(0x01) when ever a non deault session is active and when the session timeout (S3 server)timing reaches without receiving any diag request , the DSL shall reset to the deault session by calling mode switch api of mode switch interface\nKeep track of active nond efault sessions\nAllow modifying timings DCM mdoule handle the following protocol timing parameter P2ServerMin,P2ServerMax,P2*ServerMin,P2*ServerMax,S3Server Generally these parameter set as\n\n\n\n\n\nHandling of Full/Silent/No Communication\nIndicating of active/inactive diagnostic\nEnabling/Disabling all kinds of diagnostic transmissions\n\n\n\n\n\n\nIt checks the validity of an incoming diagnostic request such as - Verification of diagnostic session - Security access levels - Application permission And keeps track of the progress of a service request execution\nThe DSD shall process only valid requests and shall reject invalid ones\n\n\n\nReceive a request message and transmit positive response message\n\nThe DSD ensures the validity of the request message.In this case if the request is valid the response will be positive .The request will be forwarded to the data process in the DSP. after DSP completes it triggers the transmission of response message by the DSD. If the response processing takes more time by the DSP may be waiting for read/write operation to eeprom then the response pending is covered by the DSL . When the request diag received the corresponding DcmPduId is blocked by the DSL .During the processing of this request , no other request of the same protocol type can be received, until the corresponding response message is sent and the DcmPduId if released again\n\nReceive a request message and supress the positive response\n\nIf the suppress positive response bit is set in the diag request in msb bit of sub function parameter .this kind of message completely handled by the DSD\n\nReceieve a request message and suppress the negative response\n\nIn case of functional addressing the DSD shall suppress the negative response for NRC 0x11 , 0x12 and 0x31\n\nReceive a request messahe and trasmit the negative response message\n\nDiag request is not valid or any condition not met to send the positive response the negative responses will be sent . In this case the DSP trigger a negative response with nrc indicating why the request was rejected . In case of 0x22 service if more than one did read operation is requested and if not all of the requested read did not failed only for the passed did the response will be sent .\n\nSend a positive response message without corresponding request\n\nThere are two services in the UDS protocol where multiole responses are sent for only one request . One service is used to enable(and disable)an event or time triggered transmission of another service , which is sent byt he ECU without a corresponding request. These services are \n\nRead Data by periodic identifier(0x2A)\nReponse on Event(0x86) These service handling is controlled by the DSL.However,DSD also provides the possibility to generate a response without a corresponding request.\n\n\nSegemented responses(Paged buffer):\n\nServices such as 0x19 and 0x36 exchange huge amount of data. So in this case the ecu internal buffer must be large enough to keep the longest data message which is to be exchnaged and the complete buffer is filled before the transmission is started . In a more RAM memory saving approach the buffer is filled only partly , transmitted partly and then refilled partly and so on. This paging mechanism rewuires only a reduced amount of memory but demands a well defined reaction time for buffer refilling . The user can decide whether to use the linear buffer or paged bugger for diagnostic\n\n#### DSD interaction with other modules\n\nDelegates the processing of request to the DSP\nKeeps track of request processing\nTransmit the response of the application to the DSL\n\n#### Functional description\n\nThe DSD shall be triggered by the DSL , if a new diagnostic message is recognised .\nThe DSD will sart processing by analyzing the diagnostic service indentifier contained in the received diagnositc message\nif the newly received the diagnositc request sid is not supported then the DSD shall transmit the negative response with NRC 0x11 to the DSL.\nVerification Functionality :The DSD accept service only if below 3 verifications are passed\n\nVerification of the Diagnostic session: On receiving the uds request dsd gets the current diagnostic session using api Dcm_GetSesCtrlType and verify whether the requested service and sub function are allowed in the current diagnostic session or not . (Note :0x10 service handling not part of DSD) If the received diag service is not allowed in the current diag session the DSD transmit the negative response with NRC 0x7F (service not supported in the active session)to the DSL submodule. If the received diag service is allowed in the current diag session but the sub function is not allowed in the current diag session then the DSD transmit the negative response with NRC 0x7E (sub function not supported in the active session)to the DSL submodule.\nVerification of the service security access levels:\n\nThe DSD checks the current security level with api Dcm_GetSecurityLevel() If the received diag service is not allowed in the current security level then the DSD shall transmit negative response with NRC 0x33 (Security access denied) to the DSL submodule\n\nIf the received diag service is n allowed in the current security level but the requested sub function is not allowed then the DSD shall transmit negative response with NRC 0x33 (Security access denied) to the DSL submodule DSD checks whether subfunction supported , if not supported NRC 0x12 will be sent . DSD checks minimum message length\nVerification of the application environment/Permission Before processing the diag request the application requested to check permission /environment eg: if ecu is in run state the diag service execution not allowed , vehicle speed is higher then the service is not allowed to execute(eg : service 11)\n\n\nThe DSD pass the diag request to DSP service interpretor\nThe execution of the DSP service interpreter can have the results\n\nPositive result or\nNegative result\n\nFollowing possible responses can be assembled\n\nPositive response : DSP indicate calling Dcm_ExternalProcessingDone().The parameter Dcm_MsgContextType contains the diagnostic (response)messgae . Then the DSD adds the response SIDand then response data stream (returned by the application)in the parameter Dcm_MsgContextType\nNegative response : The DSP triggers specific NRC to the DSD . The DSD handle all the supported NRC from the application and defined in the Dcm_NegativeResponseCodeType.\nSuppression of response in case of a negative result of the execution and active functional addressing the dsd submodule shall activate the suppression of the following negative responses:\n\n\nNRC 0x011 - service not supported\nNRC 0x12 - subfunction not supported\nNRC 0x31 - request out of range\n\n\nno Response :\nInitiate transmission\n\nthe DSD shall forward the diagnostic(response)message (positive or negative response) to the DSL.\nthe DSL shall forward the diagnostic(response)message (positive or negative response)further to the PduR module by executing a DSL transmit functionality.\nThe DSL will receive the confirmation by the PduR upon forwarding the dada\n\nthe DSL shall forward the received confirmation from the PduR to the dsd submodule.\nthe dsd shall forward the confirmation via the internal function DspInternal_DcmConfirmation() to the DSP submodule.\nIn case no diagnostic(response)message shall be sent(suppression of responses)the DSL submodule shall not transmit any response.\n\n\n\n\n\n\n\n\nWhen dsd request the dsp to process the diag request .it executed following basic process 1. analyze the received request message 2. check format and whether the addressed subfunction is supported 3. aquire data or execute the required function call on the DEM, SW-Cs or other BSW modules 4. assemble the response\n\nThe DSP submodule will check for appropriate message length and structure before executing the requested command . the DSP triggers a negative response with NRC 0x13 when the analysis of the request message results in formatting or length failure.\nif the paged-buffer mechanism is used the DSP submodule shall determine the overall response length before any data is passed to the DSD submodule respectively. The DSP submodule shall confirm the completion of the request processing with the function call Dcm_ExternalProcessingDone()"
  },
  {
    "objectID": "Autosar/DEM.html",
    "href": "Autosar/DEM.html",
    "title": "Diagnostic event manager",
    "section": "",
    "text": "The DEM module provides function to retrieve all information related to fault memory such that the DCM module is able to respond to tester requests by reading data from the fault memory\nPDUR :\nDCM is devided in to 3 parts\n\n\nDSL-Diagnostic Session Layer\nDiagnostic Service Dispatcher\nDiagnostic Service Processing"
  },
  {
    "objectID": "Autosar/DEM.html#description",
    "href": "Autosar/DEM.html#description",
    "title": "Diagnostic event manager",
    "section": "",
    "text": "The DEM module provides function to retrieve all information related to fault memory such that the DCM module is able to respond to tester requests by reading data from the fault memory\nPDUR :\nDCM is devided in to 3 parts\n\n\nDSL-Diagnostic Session Layer\nDiagnostic Service Dispatcher\nDiagnostic Service Processing"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Auto Glimpses",
    "section": "",
    "text": "Home page Author: Yasmi"
  },
  {
    "objectID": "C_Plus_Plus/Basics/basics_cpp.html",
    "href": "C_Plus_Plus/Basics/basics_cpp.html",
    "title": "Glimpse of C++",
    "section": "",
    "text": "#include&lt;iostream&gt;\nusing namespace std;\n\ntypedef struct \n{\n    const char * name;\n    int ranking;\n    int studentid;\n}studentdataBase;\n\nclass lecture;\n\n class student\n{\n    public:\n    static const studentdataBase studentdataBasec[2];\n\n    friend class lecture;\n};\n\nclass lecture\n    {\n        public:\n        void printstudentData()\n        {\n        cout&lt;&lt;student::studentdataBasec[1].name&lt;&lt;endl;\n        }\n     \n};\n\n\n const studentdataBase student::studentdataBasec[2]=\n{\n    {\n        \"Disha\",\n        1,\n        1234\n    },\n    {\n        \"Isha\",\n        2,\n        4567\n    }\n};\n\nint main()\n{\n    lecture obj;\n    obj.printstudentData();\n\n    return 0;\n}\n\nIn the above program lecture is the friend function of student\nlecture class gets to access the members of class student"
  },
  {
    "objectID": "C_Plus_Plus/Basics/basics_cpp.html#friend-function",
    "href": "C_Plus_Plus/Basics/basics_cpp.html#friend-function",
    "title": "Glimpse of C++",
    "section": "",
    "text": "#include&lt;iostream&gt;\nusing namespace std;\n\ntypedef struct \n{\n    const char * name;\n    int ranking;\n    int studentid;\n}studentdataBase;\n\nclass lecture;\n\n class student\n{\n    public:\n    static const studentdataBase studentdataBasec[2];\n\n    friend class lecture;\n};\n\nclass lecture\n    {\n        public:\n        void printstudentData()\n        {\n        cout&lt;&lt;student::studentdataBasec[1].name&lt;&lt;endl;\n        }\n     \n};\n\n\n const studentdataBase student::studentdataBasec[2]=\n{\n    {\n        \"Disha\",\n        1,\n        1234\n    },\n    {\n        \"Isha\",\n        2,\n        4567\n    }\n};\n\nint main()\n{\n    lecture obj;\n    obj.printstudentData();\n\n    return 0;\n}\n\nIn the above program lecture is the friend function of student\nlecture class gets to access the members of class student"
  },
  {
    "objectID": "C_Plus_Plus/Basics/basics_cpp.html#casting-in-c",
    "href": "C_Plus_Plus/Basics/basics_cpp.html#casting-in-c",
    "title": "Glimpse of C++",
    "section": "2 Casting in C++",
    "text": "2 Casting in C++\n\n2.1 const_cast&lt;Type&gt;(variable)\nconst_cast Its used to change the const or volatile qualifiers of pointers or referances . where type should be either pointer, reference or pointer to member type\nint main()\n{\n    int a=5;\n    const int *p=&a;\n    int *b=const_cast&lt;int*&gt;(p)\n    *b=10;\n    cout&lt;&lt;*b&lt;&lt;endl;\n    return 0;\n}\n\nResult=10;\n\n\n\n2.2 static_cast&lt;Type&gt;(variable)\nIts an implicity conversion in c++\nint main()\n{\n    char c='a';\n    int data=static_cast&lt;int&gt;(a);\n    cout&lt;&lt;data&lt;&lt;endl;\n    return 0;\n}\n\nResult=10;\n\n\n\n2.3 reinterpret_cast&lt;Type&gt;(variable)\nIt is used to cast any pointer type to any pointer type\nint main()\n{\n    int a=5;\n    int *iptr=&a;\n    char *cptr=reinterpret_cast&lt;char*&gt;(&iptr);\n    cout&lt;&lt;*cptr&lt;&lt;endl;\n    return 0;\n}\n\n\n2.4 dynamic_cast&lt;Type&gt;(variable)\nIts used for safe downcasting at run time. The dynamic_cast to work atleast one virtual function is necessory in the base class\nclass base\n{\n    public :\n    virtual void print()\n    {\n        cout&lt;&lt;\"hey\"&lt;&lt;endl;\n    }\n};\n\nclass derived : public base\n{\n    public :\n    virtual void print()override\n    {\n        cout&lt;&lt;\"hey derived\"&lt;&lt;endl;\n    }\n};\nint main()\n{\n    derived d_obj;\n    base *b_obj=dynamic_cast&lt;derived*&gt;(&d_obj);\n    b_obj-&gt;print();\n}\n\nResult=hey derived"
  },
  {
    "objectID": "C_Plus_Plus/Advanced/advanced_cpp.html",
    "href": "C_Plus_Plus/Advanced/advanced_cpp.html",
    "title": "Advanced C++ study",
    "section": "",
    "text": "A class template is prescription for creating a class in which one or more types or values are prameterized .\nLet us see how to define and declare class templates  template &lt;class T&gt;\n\ntemplate key word always begins both the definition and a declaration of a class template .\ntemplate key word is followed by list of user defined data type separated by comma\nand surrounded by the less than (&lt;) and greater than (&gt;) tokens.\nIn place of class key word typename could also be used as shown below template &lt;typename T&gt;\n\nBelow is the simple program to understand the template class\n#include &lt;iostream&gt;\nusing namespace std;\n\ntemplate &lt;class ValueType&gt;\nclass tempClass\n{\npublic:\ntempClass(){}\nvoid updateDataType(ValueType data);\n\n};\n\ntemplate &lt;class ValueType&gt;\nvoid tempClass &lt; ValueType&gt;::updateDataType(ValueType data)\n{\n cout &lt;&lt;\"data=\"&lt;&lt;data&lt;&lt;endl;\n}\nint main()\n{\n    tempClass&lt;int&gt; tempObject;\n    tempObject.updateDataType(5);\n\n    tempClass&lt;char&gt; tempObjectchar;\n    char value='a';\n    tempObject.updateDataType(value);\n    return 0;\n}\ntemplate class can also have nontype parameter ,mostly it will be constant template &lt;class T, int size&gt;\n#include &lt;iostream&gt;\nusing namespace std;\n\ntemplate &lt;class ValueType&gt;\nclass tempClass\n{\npublic:\ntempClass(){}\nvoid updateDataType(ValueType data);\n\n};\n\ntemplate &lt;class ValueType&gt;\nvoid tempClass &lt; ValueType&gt;::updateDataType(ValueType data)\n{\n cout &lt;&lt;\"data=\"&lt;&lt;data&lt;&lt;endl;\n}\nint main()\n{\n    tempClass&lt;int&gt; tempObject;\n    tempObject.updateDataType(5);\n\n    tempClass&lt;char&gt; tempObjectchar;\n    char value='a';\n    tempObject.updateDataType(value);\n    return 0;\n}"
  },
  {
    "objectID": "C_Plus_Plus/Advanced/advanced_cpp.html#class-templates",
    "href": "C_Plus_Plus/Advanced/advanced_cpp.html#class-templates",
    "title": "Advanced C++ study",
    "section": "",
    "text": "A class template is prescription for creating a class in which one or more types or values are prameterized .\nLet us see how to define and declare class templates  template &lt;class T&gt;\n\ntemplate key word always begins both the definition and a declaration of a class template .\ntemplate key word is followed by list of user defined data type separated by comma\nand surrounded by the less than (&lt;) and greater than (&gt;) tokens.\nIn place of class key word typename could also be used as shown below template &lt;typename T&gt;\n\nBelow is the simple program to understand the template class\n#include &lt;iostream&gt;\nusing namespace std;\n\ntemplate &lt;class ValueType&gt;\nclass tempClass\n{\npublic:\ntempClass(){}\nvoid updateDataType(ValueType data);\n\n};\n\ntemplate &lt;class ValueType&gt;\nvoid tempClass &lt; ValueType&gt;::updateDataType(ValueType data)\n{\n cout &lt;&lt;\"data=\"&lt;&lt;data&lt;&lt;endl;\n}\nint main()\n{\n    tempClass&lt;int&gt; tempObject;\n    tempObject.updateDataType(5);\n\n    tempClass&lt;char&gt; tempObjectchar;\n    char value='a';\n    tempObject.updateDataType(value);\n    return 0;\n}\ntemplate class can also have nontype parameter ,mostly it will be constant template &lt;class T, int size&gt;\n#include &lt;iostream&gt;\nusing namespace std;\n\ntemplate &lt;class ValueType&gt;\nclass tempClass\n{\npublic:\ntempClass(){}\nvoid updateDataType(ValueType data);\n\n};\n\ntemplate &lt;class ValueType&gt;\nvoid tempClass &lt; ValueType&gt;::updateDataType(ValueType data)\n{\n cout &lt;&lt;\"data=\"&lt;&lt;data&lt;&lt;endl;\n}\nint main()\n{\n    tempClass&lt;int&gt; tempObject;\n    tempObject.updateDataType(5);\n\n    tempClass&lt;char&gt; tempObjectchar;\n    char value='a';\n    tempObject.updateDataType(value);\n    return 0;\n}"
  },
  {
    "objectID": "C_Plus_Plus/Advanced/advanced_cpp.html#lambda-function",
    "href": "C_Plus_Plus/Advanced/advanced_cpp.html#lambda-function",
    "title": "Advanced C++ study",
    "section": "2 Lambda function",
    "text": "2 Lambda function\nFormat :\n[] () mutable throw() -&gt; int \n{\n    //lambda body\n} \n[] Lambda introducer also called capture clause  () Lambda declarator also called parameter list  mutable also known as mutable specification  exception specification return type lambda body\nCapture clause \n[] -lambda does not access enclosing scope [=] -captures everything by value  [&]-capture everything by reference [x,&y]-capture x by value and y by reference [&,z]-capture everything by reference,but z by value \nLambda function example \n int x=9;\n  auto add_one = [x] (const int value) \n    {\n        x=2;//Error \n\n         //x is captured by copy so the x value cannot be modified inside the lambda function \n        //in order to change/update the value of x add \"mutable keyword after parameter list \"\n        //or capture the x value by reference in the capture clause\n        return value + 1+x;\n    };\n  \n  //Method 1\n    auto add_one = [x] (const int value) mutable\n    {\n        x=2;\n        return value + 1+x;\n    };\n    cout&lt;&lt;(add_one(2))&lt;&lt;endl; //12\n\n     //Method 2\n    auto add_one = [&x] (const int value) \n    {\n        x=2;\n        return value + 1+x;\n    };\n    cout&lt;&lt;(add_one(2))&lt;&lt;endl;//12"
  },
  {
    "objectID": "C_Plus_Plus/Linked-list/linkedlist_basics.html",
    "href": "C_Plus_Plus/Linked-list/linkedlist_basics.html",
    "title": "Linkedlist Basics",
    "section": "",
    "text": "// Created by Yasmi on 13/11/24.\n\n#include &lt;iostream&gt;\n\nclass Node\n{\npublic:\n    int data;\n    Node *next;\n\n    explicit Node(int data): data(data), next(nullptr)\n    {\n    }\n\n    Node(int data, Node *next): data(data), next(nullptr)\n    {\n    }\n};\n\nclass singleLinkedList\n{\npublic:\n    Node *head;\n\n    singleLinkedList(): head(nullptr)\n    {\n    }\n\n    void insertAtHead(int data)\n    {\n        if (head == nullptr)\n        {\n            head = new Node(data);\n        }\n        else\n        {\n            auto *newNode = new Node(data);\n            newNode-&gt;next = head;\n            head = newNode;\n\n        }\n    }\n\n    void insertAtTail(int data)\n    {\n        if (head == nullptr)\n        {\n            head = new Node(data);\n        }\n        else\n        {\n            Node *temp = head;\n            while (temp-&gt;next != nullptr)\n            {\n                temp = temp-&gt;next;\n            }\n\n            temp-&gt;next = new Node(data);\n        }\n    }\n\n    void insertAtanyPosition(int data, int position)\n    {\n        if (head == nullptr)\n        {\n            head = new Node(data);\n        }\n        else\n        {\n            int currentPos = 1;\n            Node *temp = head;\n            Node *previous = nullptr;\n            while (temp != nullptr && currentPos &lt; position)\n            {\n\n                currentPos++;\n                previous = temp;\n                temp = temp-&gt;next;\n            }\n\n            if (currentPos == position)\n            {\n                Node *newNode = new Node(data);\n                newNode-&gt;next = temp;\n                previous-&gt;next = newNode;\n            }\n        }\n    }\n\n    void deleteFromPosition(int position)\n    {\n        int currentPos = 1;\n        Node *temp = head;\n        Node *previous = nullptr;\n        while (temp != nullptr && currentPos &lt; position)\n        {\n            currentPos++;\n            previous = temp;\n            temp = temp-&gt;next;\n        }\n\n        if (currentPos == position)\n        {\n            previous-&gt;next = temp-&gt;next;\n        }\n    }\n\n    void display() const\n    {\n        if (head == nullptr)\n        {\n            std::cout &lt;&lt; \"List is empty\" &lt;&lt; std::endl;\n        }\n        else\n        {\n            const Node *temp = head;\n            while (temp != nullptr)\n            {\n                std::cout &lt;&lt; temp-&gt;data &lt;&lt; \" \";\n                temp = temp-&gt;next;\n            }\n            std::cout &lt;&lt; std::endl;\n        }\n\n    }\n\n    ~singleLinkedList()\n    {\n        if (head != nullptr)\n        {\n            const Node *temp = head;\n            while (temp != nullptr)\n            {\n                const Node *nextNode = temp-&gt;next;\n                delete temp;\n                temp = nextNode;\n            }\n\n        }\n    }\n};\n\nint main()\n{\n    singleLinkedList obj;\n    obj.insertAtHead(12);\n    obj.insertAtTail(24);\n    obj.insertAtTail(36);\n    obj.insertAtTail(48);\n    obj.insertAtTail(94);\n    std::cout &lt;&lt; \"list before modification\" &lt;&lt; std::endl;\n    obj.display();\n    std::cout &lt;&lt; \"list after modification\" &lt;&lt; std::endl;\n    obj.insertAtanyPosition(72, 5);\n    obj.display();\n    std::cout &lt;&lt; \"list after deleting\" &lt;&lt; std::endl;\n    obj.deleteFromPosition(4);\n    obj.display();\n    return 0;\n}\nOutput :\nlist before modification\n12 24 36 48 94 \nlist after modification\n12 24 36 48 72 94 \nlist after deleting\n12 24 36 72 94"
  },
  {
    "objectID": "C_Plus_Plus/Linked-list/linkedlist_basics.html#single-linkedlist",
    "href": "C_Plus_Plus/Linked-list/linkedlist_basics.html#single-linkedlist",
    "title": "Linkedlist Basics",
    "section": "",
    "text": "// Created by Yasmi on 13/11/24.\n\n#include &lt;iostream&gt;\n\nclass Node\n{\npublic:\n    int data;\n    Node *next;\n\n    explicit Node(int data): data(data), next(nullptr)\n    {\n    }\n\n    Node(int data, Node *next): data(data), next(nullptr)\n    {\n    }\n};\n\nclass singleLinkedList\n{\npublic:\n    Node *head;\n\n    singleLinkedList(): head(nullptr)\n    {\n    }\n\n    void insertAtHead(int data)\n    {\n        if (head == nullptr)\n        {\n            head = new Node(data);\n        }\n        else\n        {\n            auto *newNode = new Node(data);\n            newNode-&gt;next = head;\n            head = newNode;\n\n        }\n    }\n\n    void insertAtTail(int data)\n    {\n        if (head == nullptr)\n        {\n            head = new Node(data);\n        }\n        else\n        {\n            Node *temp = head;\n            while (temp-&gt;next != nullptr)\n            {\n                temp = temp-&gt;next;\n            }\n\n            temp-&gt;next = new Node(data);\n        }\n    }\n\n    void insertAtanyPosition(int data, int position)\n    {\n        if (head == nullptr)\n        {\n            head = new Node(data);\n        }\n        else\n        {\n            int currentPos = 1;\n            Node *temp = head;\n            Node *previous = nullptr;\n            while (temp != nullptr && currentPos &lt; position)\n            {\n\n                currentPos++;\n                previous = temp;\n                temp = temp-&gt;next;\n            }\n\n            if (currentPos == position)\n            {\n                Node *newNode = new Node(data);\n                newNode-&gt;next = temp;\n                previous-&gt;next = newNode;\n            }\n        }\n    }\n\n    void deleteFromPosition(int position)\n    {\n        int currentPos = 1;\n        Node *temp = head;\n        Node *previous = nullptr;\n        while (temp != nullptr && currentPos &lt; position)\n        {\n            currentPos++;\n            previous = temp;\n            temp = temp-&gt;next;\n        }\n\n        if (currentPos == position)\n        {\n            previous-&gt;next = temp-&gt;next;\n        }\n    }\n\n    void display() const\n    {\n        if (head == nullptr)\n        {\n            std::cout &lt;&lt; \"List is empty\" &lt;&lt; std::endl;\n        }\n        else\n        {\n            const Node *temp = head;\n            while (temp != nullptr)\n            {\n                std::cout &lt;&lt; temp-&gt;data &lt;&lt; \" \";\n                temp = temp-&gt;next;\n            }\n            std::cout &lt;&lt; std::endl;\n        }\n\n    }\n\n    ~singleLinkedList()\n    {\n        if (head != nullptr)\n        {\n            const Node *temp = head;\n            while (temp != nullptr)\n            {\n                const Node *nextNode = temp-&gt;next;\n                delete temp;\n                temp = nextNode;\n            }\n\n        }\n    }\n};\n\nint main()\n{\n    singleLinkedList obj;\n    obj.insertAtHead(12);\n    obj.insertAtTail(24);\n    obj.insertAtTail(36);\n    obj.insertAtTail(48);\n    obj.insertAtTail(94);\n    std::cout &lt;&lt; \"list before modification\" &lt;&lt; std::endl;\n    obj.display();\n    std::cout &lt;&lt; \"list after modification\" &lt;&lt; std::endl;\n    obj.insertAtanyPosition(72, 5);\n    obj.display();\n    std::cout &lt;&lt; \"list after deleting\" &lt;&lt; std::endl;\n    obj.deleteFromPosition(4);\n    obj.display();\n    return 0;\n}\nOutput :\nlist before modification\n12 24 36 48 94 \nlist after modification\n12 24 36 48 72 94 \nlist after deleting\n12 24 36 72 94"
  },
  {
    "objectID": "C_Plus_Plus/Linked-list/linkedlist_basics.html#double-linkedlist",
    "href": "C_Plus_Plus/Linked-list/linkedlist_basics.html#double-linkedlist",
    "title": "Linkedlist Basics",
    "section": "2 double linkedlist",
    "text": "2 double linkedlist\n\n\n#include &lt;iostream&gt;\n\nclass Node\n{\npublic:\n    int data;\n    Node *next;\n    Node *prev;\n\n    explicit Node(int data): data(data), next(nullptr),prev(nullptr){}\n\n    Node(int data, Node *next,Node* prev ): data(data), next(nullptr), prev(prev){}\n};\n\nclass doubleLinkedList\n{\npublic:\n    Node *head;\n\n    doubleLinkedList(): head(nullptr){}\n\n    void insertAtHead(int data)\n    {\n        if(head==nullptr)\n        {\n            head = new Node(data);\n        }\n        else\n        {\n            auto *newNode = new Node(data);\n            head-&gt;prev = newNode;\n            newNode-&gt;next = head;\n            head = newNode;\n            head-&gt;prev = nullptr;\n\n        }\n    }\n\n    void insertAtTail(int data)\n    {\n        if(head==nullptr)\n        {\n            head = new Node(data);\n        }\n        else\n        {\n            Node * temp=head;\n            while(temp-&gt;next!=nullptr)\n            {\n                temp=temp-&gt;next;\n            }\n            Node* newNode = new Node(data);\n            newNode-&gt;prev=temp;\n            temp-&gt;next=newNode;\n        }\n    }\n\n    void insertAtanyPosition(int data,int position)\n    {\n        if(head==nullptr)\n        {\n            head = new Node(data);\n        }\n        else\n        {\n            int currentPos=1;\n            Node * temp=head;\n            Node * previous=nullptr;\n            while(temp!=nullptr && currentPos&lt;position)\n            {\n                currentPos++;\n                temp=temp-&gt;next;\n            }\n\n            if(currentPos==position)\n            {\n                Node * newNode = new Node(data);\n                newNode-&gt;next=temp;\n                temp-&gt;prev-&gt;next=newNode;\n                newNode-&gt;prev=temp-&gt;prev;\n                temp-&gt;prev=newNode;\n            }\n        }\n    }\n\n    void deleteFromPosition(int position)\n    {\n            int currentPos=1;\n            Node * temp=head;\n            while(temp!=nullptr && currentPos&lt;position)\n            {\n                currentPos++;\n                temp=temp-&gt;next;\n            }\n\n            if(currentPos==position)\n            {\n                temp-&gt;prev-&gt;next=temp-&gt;next;\n                temp-&gt;next-&gt;prev=temp-&gt;prev;\n            }\n    }\n    void display() const\n    {\n        if(head==nullptr)\n        {\n            std::cout&lt;&lt;\"List is empty\"&lt;&lt;std::endl;\n        }\n        else\n        {\n            const Node * temp=head;\n            while(temp!=nullptr)\n            {\n                std::cout&lt;&lt;temp-&gt;data&lt;&lt;\" \";\n                temp=temp-&gt;next;\n            }\n            std::cout&lt;&lt;std::endl;\n        }\n\n    }\n\n    ~doubleLinkedList()\n    {\n        if(head!=nullptr)\n        {\n           const Node * temp=head;\n            while(temp!=nullptr)\n            {\n                const Node * nextNode=temp-&gt;next;\n                delete temp;\n                temp=nextNode;\n            }\n\n        }\n    }\n};\n\nint main()\n{\n    doubleLinkedList obj;\n    obj.insertAtHead(12);\n    obj.insertAtTail(24);\n    obj.insertAtHead(6);\n    obj.insertAtTail(36);\n    obj.insertAtTail(48);\n    obj.insertAtTail(94);\n    std::cout&lt;&lt;\"list before modification\" &lt;&lt; std::endl;\n    obj.display();\n    std::cout&lt;&lt;\"list after modification\" &lt;&lt; std::endl;\n    obj.insertAtanyPosition(72,6);\n    obj.display();\n    std::cout&lt;&lt;\"list after deletion\" &lt;&lt; std::endl;\n    obj.deleteFromPosition(5);\n    obj.display();\n    return 0;\n}\nOutput:\nlist before modification\n6 12 24 36 48 94 \nlist after modification\n6 12 24 36 48 72 94 \nlist after deletion\n6 12 24 36 72 94"
  },
  {
    "objectID": "Notes/index.html",
    "href": "Notes/index.html",
    "title": "Notes",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nNotes\n\n\n\n\n\n\n\nNotes\n\n\n\n\nNotes\n\n\n\n\n\n\nAug 26, 2022\n\n\nYasmi\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "C_Plus_Plus/Linked-list/circular_linkedlist.html#section",
    "href": "C_Plus_Plus/Linked-list/circular_linkedlist.html#section",
    "title": "circularLinkedList",
    "section": "2 ",
    "text": "2"
  }
]